{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451ebe8f-fa69-4cdc-aebc-96a926541a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, BertTokenizer, BertForTokenClassification, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "from tqdm import tqdm_notebook\n",
    "from uuid import uuid4\n",
    "\n",
    "import json \n",
    "\n",
    "import spacy\n",
    "\n",
    "## Torch Modules\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ebee3c-dfd8-4f78-abf5-5a2031f1b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/naver/biobert-pretrained/releases/download/v1.1-pubmed/biobert_v1.1_pubmed.tar.gz\n",
    "\n",
    "# !tar -xvzf biobert_v1.1_pubmed.tar.gz\n",
    "\n",
    "# !export BERT_BASE_DIR=biobert_v1.1_pubmed\n",
    "\n",
    "# !pip install tensorflow\n",
    "\n",
    "# !pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch biobert_v1.1_pubmed/model.ckpt-1000000 biobert_v1.1_pubmed/bert_config.json biobert_v1.1_pubmed/pytorch_model.bin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabcd3b2-8ffe-4b32-a52d-1a6b31a66efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -cvzf biobert.gz biobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceb33f0e-9895-4351-b3b1-60ac65306f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974f52db-216d-4010-b029-6c75b0a7b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertModel\n",
    "model = BertModel.from_pretrained('biobert_v1.1_pubmed')\n",
    "tokenizer = BertTokenizer(vocab_file='biobert_v1.1_pubmed/vocab.txt', do_lower_case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "467f05f4-f8bd-4c15-b9e5-e3de48b19464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef56ac63-7773-4ba4-9e97-68980181784e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe107c7-0843-44b3-a95a-07f5dc9e272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b02cd07-a020-4ef1-90ee-3cb0a316efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('pah/data/train_fs.tsv', delimiter = '\\t', header = None)\n",
    "test_data = pd.read_csv('pah/data/dev_fs.tsv', delimiter = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08640f9f-2956-4ebc-af8d-b72fd614d0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rel</td>\n",
       "      <td>Methods In this double-blind , placebo-control...</td>\n",
       "      <td>dosage</td>\n",
       "      <td>drug</td>\n",
       "      <td>T_133115</td>\n",
       "      <td>T_13350</td>\n",
       "      <td>F_133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NotRel</td>\n",
       "      <td>In a preliminary study , the orally administer...</td>\n",
       "      <td>drug</td>\n",
       "      <td>reason</td>\n",
       "      <td>T_1331</td>\n",
       "      <td>T_133113</td>\n",
       "      <td>F_133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rel</td>\n",
       "      <td>Methods In this double-blind , placebo-control...</td>\n",
       "      <td>drug</td>\n",
       "      <td>duration</td>\n",
       "      <td>T_1335</td>\n",
       "      <td>T_1331161</td>\n",
       "      <td>F_133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rel</td>\n",
       "      <td>Methods In this double-blind , placebo-control...</td>\n",
       "      <td>drug</td>\n",
       "      <td>dosage</td>\n",
       "      <td>T_1336</td>\n",
       "      <td>T_1331172</td>\n",
       "      <td>F_133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rel</td>\n",
       "      <td>Methods In this double-blind , placebo-control...</td>\n",
       "      <td>drug</td>\n",
       "      <td>duration</td>\n",
       "      <td>T_1336</td>\n",
       "      <td>T_1331183</td>\n",
       "      <td>F_133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1       2  \\\n",
       "0     Rel  Methods In this double-blind , placebo-control...  dosage   \n",
       "1  NotRel  In a preliminary study , the orally administer...    drug   \n",
       "2     Rel  Methods In this double-blind , placebo-control...    drug   \n",
       "3     Rel  Methods In this double-blind , placebo-control...    drug   \n",
       "4     Rel  Methods In this double-blind , placebo-control...    drug   \n",
       "\n",
       "          3         4          5      6  \n",
       "0      drug  T_133115    T_13350  F_133  \n",
       "1    reason    T_1331   T_133113  F_133  \n",
       "2  duration    T_1335  T_1331161  F_133  \n",
       "3    dosage    T_1336  T_1331172  F_133  \n",
       "4  duration    T_1336  T_1331183  F_133  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fcd1ec0-762d-4c49-b814-9461c51e41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[[0,1]]\n",
    "train_data.columns = ['label','utterance']\n",
    "\n",
    "test_data = test_data[[0,1]]\n",
    "test_data.columns = ['label','utterance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58465e15-06f6-49f0-a188-0d0880454de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(tokenizer, seq_1, max_seq_length = 300, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True):\n",
    "    ## Tokenzine Input\n",
    "    tokens_a = tokenizer.tokenize(seq_1)\n",
    "\n",
    "    ## Truncate\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "    ## Initialize Tokens\n",
    "    tokens = []\n",
    "    if include_CLS_token:\n",
    "        tokens.append(tokenizer.cls_token)\n",
    "    ## Add Tokens and separators\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "\n",
    "    if include_SEP_token:\n",
    "        tokens.append(tokenizer.sep_token)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    # input_ids = input_ids.squeeze(0)\n",
    "    ## Input Mask \n",
    "    input_mask = [1] * len(input_ids)\n",
    "    ## Zero-pad sequence lenght\n",
    "    if zero_pad:\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "    return torch.tensor(input_ids).unsqueeze(0), input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d400279-f507-4239-af90-0749a325ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relations(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.utterance[index]\n",
    "        label = self.data.label[index]\n",
    "        X, _  = prepare_features(tokenizer, utterance)\n",
    "        y = label_to_ix[self.data.label[index]]\n",
    "        return X,y #{k: v[index] for k, v in zip(X,y)}#\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc16bed0-a314-4723-b429-71ae105264e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relations_B(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.utterance[index]\n",
    "        label = self.data.label[index]\n",
    "        # X, _  = prepare_features(tokenizer, utterance)\n",
    "        y = label_to_ix[self.data.label[index]]\n",
    "        return utterance,y #{k: v[index] for k, v in zip(X,y)}#\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9356576e-5068-4507-9377-50990bf4519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df[['label','tokens']]\n",
    "train_data.columns = ['label','utterance']\n",
    "\n",
    "test_data = test_df[['label','tokens']]\n",
    "test_data.columns = ['label','utterance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8893268-6be0-43f9-8566-a03c8d84cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Relations(train_data)\n",
    "testing_set = Relations(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccc1849f-242c-4626-add9-03aac4025a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Relations_B(train_data)\n",
    "testing_set = Relations_B(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "315fac44-c973-41b6-a13d-0d35157a701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b66eba2f-b30c-43af-971c-cb682fdf03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 1,\n",
    "          'shuffle': True,\n",
    "          'drop_last': False,\n",
    "          'num_workers': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ce8a254-48fe-490b-b64a-923aeaed4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b6ec556-8501-459d-b19c-26b757807609",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-05\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47602e95-996f-4524-a663-93f8acdc85c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rel': 0, 'NotRel': 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix = {}\n",
    "for label in train_data.label:\n",
    "    for word in label.split():\n",
    "        if word not in label_to_ix:\n",
    "            label_to_ix[word]=len(label_to_ix)\n",
    "label_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b0eb790-9bcb-4545-8150-9f88410ad3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_jsons_aug = json.load(open('pah/data/relations_marked_train_aug.json'))\n",
    "len(train_jsons_aug)\n",
    "test_jsons_aug = json.load(open('pah/data/relations_marked_test_aug.json'))\n",
    "len(test_jsons_aug)\n",
    "inf_jsons_aug = json.load(open('pah/data/articles_inf_aa_aug.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bed398d-cac2-43af-9249-539a57a818a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = json.load(open('pah/tokenizer/vocab.json'))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d1d4dd8-2983-4d25-9efa-d73bfeeca221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35404"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train = 0\n",
    "for i in range(len(train_jsons_aug)):\n",
    "    len_train+=len(train_jsons_aug[i]['tokens'])\n",
    "len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b786847-b5ab-4f4a-a3f6-3cee8abfb767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8395"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test = 0\n",
    "for i in range(len(test_jsons_aug)):\n",
    "    len_test+=len(test_jsons_aug[i]['tokens'])\n",
    "len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7223c97-6b13-4579-9751-518972e5ccb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15407863518246526"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5455/35404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6842e6b7-4eed-408d-857e-b96720586ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5455"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train_oov = 0\n",
    "for i in range(len(train_jsons_aug)):\n",
    "    for t in train_jsons_aug[i]['tokens']:\n",
    "        if t not in vocab.keys():\n",
    "            len_train_oov+=1\n",
    "len_train_oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dddce5b-8241-43af-b500-e45064f71cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6670"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_excel('pah/data/relations_проверка_связей.xlsx')['ss1']\n",
    "tokens_test = 0\n",
    "for i in range(len(data_test)):\n",
    "    for t in str(data_test[i]).split(' '):\n",
    "        if t!='[s1]' and t!='[e1]':\n",
    "            tokens_test+=1\n",
    "tokens_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49d0982d-5b37-4807-b344-b604acb25766",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_LIST = [\".\",\",\",\":\", \"-LRB-\",\"-RRB-\",\"``\",\"\\\"\\\"\",\"''\",\",\",\"$\",\"#\",\"AFX\",\"CC\",\"CD\",\"DT\",\"EX\",\"FW\",\"HYPH\",\"IN\",\"JJ\",\"JJR\",\"JJS\",\"LS\",\"MD\",\"NIL\",\"NN\",\"NNP\",\"NNPS\",\"NNS\",\"PDT\",\"POS\",\"PRP\",\"PRP$\",\"RB\",\"RBR\",\"RBS\",\"RP\",\"SP\",\"SYM\",\"TO\",\"UH\",\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\",\"WDT\",\"WP\",\"WP$\",\"WRB\",\"ADD\",\"NFP\",\"GW\",\"XX\",\"BES\",\"HVS\",\"_SP\"]\n",
    "POS_LIST = [\"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CONJ\", \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\", \"SPACE\"]\n",
    "DEP_LIST = [\"acl\", \"acomp\", \"advcl\", \"advmod\", \"agent\", \"amod\", \"appos\", \"attr\", \"aux\", \"auxpass\", \"case\", \"cc\", \"ccomp\", \"compound\", \"conj\", \"cop\", \"csubj\", \"csubjpass\", \"dative\", \"dep\", \"det\", \"dobj\", \"expl\", \"intj\", \"mark\", \"meta\", \"neg\", \"nn\", \"npmod\", \"npadvmod\", \"nsubj\", \"nsubjpass\", \"nummod\",\"nmod\", \"oprd\", \"obj\", \"obl\", \"parataxis\", \"pcomp\",\"predet\", \"pobj\", \"poss\", \"preconj\", \"prep\", \"prt\", \"punct\",  \"quantmod\", \"relcl\", \"ROOT\", \"xcomp\"]\n",
    "NER_LIST = [\"PERSON\", \"NORP\", \"FAC\", \"ORG\", \"GPE\", \"LOC\", \"PRODUCT\", \"EVENT\", \"WORK_OF_ART\", \"LAW\", \"LANGUAGE\", \"DATE\", \"TIME\", \"PERCENT\", \"MONEY\", \"QUANTITY\", \"ORDINAL\", \"CARDINAL\"]\n",
    "\n",
    "pos_tags = {}\n",
    "for i,p in enumerate(TAG_LIST):\n",
    "    pos_tags[p] = i\n",
    "dep_tags = {}\n",
    "for i,p in enumerate(DEP_LIST):\n",
    "    dep_tags[p] = i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "567ebeca-81df-4e00-a7e7-370bb5b159ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_dict = {}\n",
    "for i in range(len(train_jsons_aug)):\n",
    "    for ent in  train_jsons_aug[i]['entities']:\n",
    "        if ent['type'] not in ent_dict:\n",
    "            ent_dict[ent['type']] = len(ent_dict)\n",
    "            \n",
    "for i in range(len(test_jsons_aug)):\n",
    "    for ent in  test_jsons_aug[i]['entities']:\n",
    "        if ent['type'] not in ent_dict:\n",
    "            ent_dict[ent['type']] = len(ent_dict)\n",
    "            \n",
    "for i in range(len(inf_jsons_aug)):\n",
    "    for ent in  inf_jsons_aug[i]['entities']:\n",
    "        if ent['type'] not in ent_dict:\n",
    "            ent_dict[ent['type']] = len(ent_dict)\n",
    "ent_dict['O'] = len(ent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62d01ab4-21ac-4553-964c-a42fb7b24395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(data):\n",
    "    df = pd.DataFrame({'tokens':[], 'pos_tags': [], 'dep_label': [], 'label': [], 'ent_type': []})\n",
    "    for index in tqdm_notebook(range(len(data))):\n",
    "        k = 0\n",
    "        ss1 = []\n",
    "        ent_types = []\n",
    "        for r in range(len(data[index]['relations'])):\n",
    "            k = 0\n",
    "            ss1 = []\n",
    "            label = data[index]['relations'][r]['type']\n",
    "            ent_types = []\n",
    "            # print(label)\n",
    "            while k<len(data[index]['tokens']):\n",
    "                if k == data[index]['entities'][data[index]['relations'][r]['head']]['start']:\n",
    "                    m = data[index]['entities'][data[index]['relations'][r]['head']]['end']\n",
    "                    ss1.append('[s1]')\n",
    "                    ss1.extend(data[index]['tokens'][k:m])\n",
    "                    ss1.append('[e1]')\n",
    "                    if k==m:\n",
    "                        m+=1\n",
    "                    for e in range(k,m):\n",
    "                        ent_types.append(data[index]['entities'][data[index]['relations'][r]['head']]['type'])\n",
    "                    k = m\n",
    "                elif k == data[index]['entities'][data[index]['relations'][r]['tail']]['start']:\n",
    "                    m = data[index]['entities'][data[index]['relations'][r]['tail']]['end']\n",
    "                    ss1.append('[s2]')\n",
    "                    ss1.extend(data[index]['tokens'][k:m])\n",
    "                    ss1.append('[e2]')\n",
    "                    if k==m:\n",
    "                        m+=1\n",
    "                    for e in range(k,m):\n",
    "                        ent_types.append(data[index]['entities'][data[index]['relations'][r]['tail']]['type'])\n",
    "                    k = m\n",
    "                else:\n",
    "                    ss1.append(data[index]['tokens'][k])\n",
    "                    ent_types.append('O')\n",
    "                    k+=1\n",
    "            df0 = pd.concat([pd.Series(' '.join(ss1)), pd.Series([[pos_tags[t] for t in data[index]['pos_tags']]]), \\\n",
    "                             pd.Series([[dep_tags[t] for t in data[index]['dep_label']]]), \n",
    "                            pd.Series([label]), pd.Series([[ent_dict[t] for t in ent_types]])], axis = 1)\n",
    "            df0.columns = df.columns\n",
    "            df = pd.concat([df, df0])\n",
    "            # df.loc[index,'tokens'] = ss1\n",
    "            # df.loc[index,'pos_tags'] = data[index]['pos_tags']\n",
    "            # df.loc[index,'dep_label'] = data[index]['dep_label']\n",
    "            # df.loc[i,'label'] = label\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4be1444-24bd-4721-b6ce-57c9b5cdf6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c66efc858a94f5f9738804287b3d192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/983 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27a8e29bfe545ffbce5375ea1c6358a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = prepare_df(train_jsons_aug)\n",
    "test_df = prepare_df(test_jsons_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fde79f2-4778-4e16-8b93-d33f40a3dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_aug(seq_2, var_dict, max_seq_length = 300, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True):\n",
    "    ## Tokenzine Input\n",
    "    tokens_a = seq_2\n",
    "\n",
    "    ## Truncate\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "    ## Initialize Tokens\n",
    "    tokens = []\n",
    "    if include_CLS_token:\n",
    "        tokens.append(tokenizer.cls_token)\n",
    "    ## Add Tokens and separators\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "\n",
    "    if include_SEP_token:\n",
    "        tokens.append(tokenizer.sep_token)\n",
    "\n",
    "    \n",
    "    input_ids = tokens_a\n",
    "    # input_ids = input_ids.squeeze(0)\n",
    "    ## Input Mask \n",
    "    input_mask = [1] * len(input_ids)\n",
    "    ## Zero-pad sequence lenght\n",
    "    if zero_pad:\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "    return torch.tensor(input_ids).unsqueeze(0), input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a3bdb06-d618-46c2-9ae0-5cc9173c5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relations_Aug(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.tokens[index]\n",
    "        label = self.data.label[index]\n",
    "        pos_seq = self.data.pos_tags[index]\n",
    "        dep_seq = self.data.dep_label[index]\n",
    "        ent_seq = self.data.ent_type[index]\n",
    "        pos_tensor, _ = prepare_features_aug(pos_seq, pos_tags, max_seq_length = 50, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "        dep_tensor, _ = prepare_features_aug(dep_seq, dep_tags, max_seq_length = 50, \n",
    "                     zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "        tok_tensor,_= prepare_features(rob_tokenizer, utterance, max_seq_length = 50, \n",
    "                     zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "        ent_tensor,_ = prepare_features_aug(ent_seq, ent_dict, max_seq_length = 50, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "        X = torch.cat((pos_tensor, dep_tensor, tok_tensor, ent_tensor), dim=1)\n",
    "        y = label_to_ix[label]\n",
    "\n",
    "        return X,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53b979da-feed-46a3-abaa-d78f371d67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_aug = Relations_Aug(train_df)\n",
    "testing_set_aug = Relations_Aug(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddded8d2-b75b-4130-bf75-6f4a6b45d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader_aug = DataLoader(training_set_aug, **params)\n",
    "testing_loader_aug = DataLoader(testing_set_aug, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f68659e4-7389-46e4-84bc-951d15145b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:61: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd3829bd2c24a03974d8c0e54e184d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0.\n",
      "Iteration: 0. Loss: 0.769384503364563. Accuracy: 61.016949152542374%. precision: 0.8620689511299133. recall: 0.5681818127632141. F1: 0.6849315166473389.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "max_epochs = 1\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('biobert_v1.1_pubmed')\n",
    "        for param in list(self.bert.parameters())[-190:]: # total  trainable 199 Params: 79 is 40%\n",
    "            param.requires_grad = False\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "          ### New layers:\n",
    "        self.linear1 = nn.Linear(768, 50)\n",
    "        self.linear2 = nn.Linear(50, 2) ## 2 is the number of classes in this example\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(768, 50), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1), nn.Sigmoid()\n",
    "            ) \n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        sequence_output, pooled_output = self.bert(\n",
    "               ids, \n",
    "               attention_mask=mask)\n",
    "            \n",
    "#         outputs = self.bert(input_ids=input_ids,\n",
    "#                             attention_mask=mask)\n",
    "\n",
    "        linear1_output = sum([self.linear1(sequence_output[:,i,:].view(-1,768)) for i in range(len(sequence_output))])/len(sequence_output) ## extract the 1st token's embeddings\n",
    "\n",
    "        # last_hidden_state_cls = sequence_output[:,0,:]\n",
    "        # prediction = self.classifier(linear1_output)\n",
    "\n",
    "\n",
    "          # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
    "#         linear1_output = sum([self.linear1(sequence_output[:,i,:].view(-1,768)) for i in range(len(sequence_output))])/len(sequence_output) ## extract the 1st token's embeddings\n",
    "\n",
    "        linear2_output = self.linear2(linear1_output)\n",
    "        output = self.classifier(sequence_output)\n",
    "\n",
    "        return linear2_output\n",
    "    \n",
    "    def get_embedding(self, ids, mask):\n",
    "        sequence_output, pooled_output = self.bert(\n",
    "               ids, \n",
    "               attention_mask=mask)\n",
    "\n",
    "        return sequence_output\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file='biobert_v1.1_pubmed/vocab.txt', do_lower_case=False)\n",
    "model = CustomBERTModel() # You can pass the parameters if required to have more flexible model\n",
    "model.to(torch.device(\"cuda\")) ## can be gpu\n",
    "criterion = nn.CrossEntropyLoss() ## If required define your own criterion\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "latest_best_score = 0\n",
    "\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH: {}.\".format(epoch))\n",
    "    for i, batch in enumerate(training_loader): ## If you have a DataLoader()  object to get the data.\n",
    "\n",
    "        data = batch[0]\n",
    "        targets = batch[1].cuda() ## assuming that data loader returns a tuple of data and its targets\n",
    "        \n",
    "        optimizer.zero_grad()   \n",
    "        encoding = tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "        input_ids = encoding['input_ids'].cuda()\n",
    "        attention_mask = encoding['attention_mask'].cuda()\n",
    "        \n",
    "        outputs = model(input_ids, mask=attention_mask)\n",
    "        outputs = F.log_softmax(outputs, dim=1)\n",
    "        \n",
    "        # targets = targets.unsqueeze(1) #, dtype = torch.float32)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            tp = 0\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            for sent, label in testing_loader:\n",
    "                # sent = sent.squeeze(1)\n",
    "                # if torch.cuda.is_available():\n",
    "                  # sent = sent.cuda()\n",
    "                  # label = label.cuda()\n",
    "                encoding = tokenizer.batch_encode_plus(sent, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "                input_ids = encoding['input_ids'].cuda()\n",
    "                attention_mask = encoding['attention_mask'].cuda()\n",
    "                output = model.forward(input_ids, mask=attention_mask)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "                tp += ((predicted.cpu() == label.cpu())&(label.cpu()==0)).sum()\n",
    "                fn += ((predicted.cpu() != label.cpu())&(label.cpu()==0)).sum()\n",
    "                fp += ((predicted.cpu() != label.cpu())&(label.cpu()==1)).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            if accuracy>latest_best_score:\n",
    "                latest_best_score = accuracy\n",
    "                torch.save(model.state_dict(), 'model_biobert_vars_'+str(epoch)+ str(uuid4())+'.pth')\n",
    "            if tp==0 and fp==0:\n",
    "                precision=0\n",
    "            else:\n",
    "                precision = tp/(tp+fp)\n",
    "            if tp==0 and fn==0:\n",
    "                recall=0\n",
    "            else:                \n",
    "                recall = tp/(tp+fn)\n",
    "            if precision == 0 and recall == 0:\n",
    "                F1 = 0\n",
    "            else:\n",
    "                F1=2*precision*recall/(precision+recall)\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%. precision: {}. recall: {}. F1: {}.'.format(i, loss.item(), accuracy, precision, recall, F1))\n",
    "\n",
    "            # accuracy = 100.00 * correct.numpy() / total\n",
    "            # print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8088d593-af2f-4c5f-a154-4c1e282f4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(bert, ids, mask):\n",
    "    sequence_output, pooled_output = bert(\n",
    "           ids, \n",
    "           attention_mask=mask)\n",
    "\n",
    "    return sequence_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66ad9ec1-d498-4ff3-9b7a-7d6bf4e1d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(test_df,index):\n",
    "    model.eval()\n",
    "    sent = test_df.utterance[index]\n",
    "    encoding = tokenizer.batch_encode_plus(sent, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "    input_ids = encoding['input_ids'].cuda()\n",
    "    attention_mask = encoding['attention_mask'].cuda()\n",
    "    outputs = model(input_ids, mask=attention_mask)[0]\n",
    "    outputs = F.log_softmax(outputs, dim=1)\n",
    "    # print(output)\n",
    "    _, predicted = torch.max(outputs.data, 0)\n",
    "    prediction=list(label_to_ix.keys())[predicted]\n",
    "    # print(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d929d09-311d-4072-abce-06af82fa2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(testing_loader):\n",
    "    predictions = []\n",
    "    for sent, label in testing_loader:\n",
    "                # sent = sent.squeeze(1)\n",
    "                # if torch.cuda.is_available():\n",
    "                  # sent = sent.cuda()\n",
    "                  # label = label.cuda()\n",
    "        encoding = tokenizer.batch_encode_plus(sent, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "        input_ids = encoding['input_ids'].cuda()\n",
    "        attention_mask = encoding['attention_mask'].cuda()\n",
    "        output = model.forward(input_ids, mask=attention_mask)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        prediction=list(label_to_ix.keys())[predicted]\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a4b3fe8-18b7-4d14-ae26-a7cdfa453457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Rel       44\n",
       " NotRel    15\n",
       " Name: label, dtype: int64,\n",
       " 0.6376811594202898)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.label.value_counts(), 44/69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "424afbf5-cbc6-45e9-bba6-672e9b0c5615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'model_biobert_vars_1217ade660-e24b-4296-83f6-4a69c856bb58.pth'\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5951e9af-0f4d-4d97-b0bb-2fc21890dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rel = []\n",
    "# for i in tqdm_notebook(range(test_data.shape[0])):\n",
    "#     test_rel.append(get_reply(test_data, i))\n",
    "pred = get_reply(testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d61201e9-c468-40e8-a494-df430bf38f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21ac04d9-cc36-477a-a158-56953f2ec2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8128723cc8bb43fb9589ed3472222178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>dep_label</th>\n",
       "      <th>label</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Comparison of hemodynamic parameters in treatm...</td>\n",
       "      <td>[25, 18, 19, 28, 18, 19, 12, 42, 28, 18, 19, 1...</td>\n",
       "      <td>[48, 43, 5, 40, 43, 5, 11, 14, 40, 43, 5, 5, 4...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Comparison of hemodynamic parameters in treatm...</td>\n",
       "      <td>[25, 18, 19, 28, 18, 19, 12, 42, 28, 18, 19, 1...</td>\n",
       "      <td>[48, 43, 5, 40, 43, 5, 11, 14, 40, 43, 5, 5, 4...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>[25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...</td>\n",
       "      <td>[13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>[25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...</td>\n",
       "      <td>[13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>[25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...</td>\n",
       "      <td>[13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             tokens  \\\n",
       "0      0  Comparison of hemodynamic parameters in treatm...   \n",
       "1      0  Comparison of hemodynamic parameters in treatm...   \n",
       "2      0  E-mail address : nazzareno.galie @ unibo.it BA...   \n",
       "3      0  E-mail address : nazzareno.galie @ unibo.it BA...   \n",
       "4      0  E-mail address : nazzareno.galie @ unibo.it BA...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [25, 18, 19, 28, 18, 19, 12, 42, 28, 18, 19, 1...   \n",
       "1  [25, 18, 19, 28, 18, 19, 12, 42, 28, 18, 19, 1...   \n",
       "2  [25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...   \n",
       "3  [25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...   \n",
       "4  [25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...   \n",
       "\n",
       "                                           dep_label   label  \\\n",
       "0  [48, 43, 5, 40, 43, 5, 11, 14, 40, 43, 5, 5, 4...  NotRel   \n",
       "1  [48, 43, 5, 40, 43, 5, 11, 14, 40, 43, 5, 5, 4...  NotRel   \n",
       "2  [13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...  NotRel   \n",
       "3  [13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...  NotRel   \n",
       "4  [13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...  NotRel   \n",
       "\n",
       "                                            ent_type  \n",
       "0  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5,...  \n",
       "1  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5,...  \n",
       "2  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  \n",
       "3  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  \n",
       "4  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = prepare_df(inf_jsons_aug)\n",
    "inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4d1e07e-47c4-47e9-9be1-04f12ff4e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df = inf_df[['tokens','label']]\n",
    "inf_df.columns = ['utterance','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09088ca0-bc3c-41ac-91d3-564b54681887",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_set = Relations_B(inf_df)\n",
    "inf_loader = DataLoader(inf_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa3bfc51-e343-4ce5-9765-ba99ea99640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_reply(inf_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa6d2bcd-1e48-4cd0-b8b6-343d821ba2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74220, (74220, 2))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred), inf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbaf245d-1e4c-431c-8ca5-5c930ec8ce37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotRel    1034\n",
       "Rel        334\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_rel)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de48233-1c7d-48b8-a85e-bc5b36c22ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Forward Pass\n",
    "inp = training_set.__getitem__(0)[0].cuda()\n",
    "output = model(inp)[0]\n",
    "print(inp.shape, output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de2936-ac4a-43af-8ae4-0ea4e73adb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd170f-8381-4abd-8dfd-5ee30f899d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.__getitem__(28)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ddfde89-0b3c-400c-ad37-b02413418ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=52000,\n",
    "    max_position_embeddings=400,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4ffd5cf-6296-45b7-bc89-ec45d381cf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(400, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizerFast,PreTrainedTokenizerFast\n",
    "\n",
    "model = RobertaForSequenceClassification(config=config)\n",
    "# for param in list(model.parameters())[-90:]: # total  trainable 199 Params: 79 is 40%\n",
    "#     param.requires_grad = False\n",
    "# rob_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "rob_tokenizer = RobertaTokenizerFast.from_pretrained(\"pah/tokenizer\", max_len=200)\n",
    "# tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"pah/tokenizer/tokenizer_file\")\n",
    "\n",
    "model_bert = BertModel.from_pretrained('biobert_v1.1_pubmed') # You can pass the parameters if required to have more flexible model\n",
    "for param in list(model_bert.parameters())[-190:]: # total  trainable 199 Params: 79 is 40%\n",
    "    param.requires_grad = False\n",
    "model_bert.to(torch.device(\"cuda\")) ## can be gpu\n",
    "model.to(torch.device(\"cuda\")) ## can be gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33bbb1bb-9a03-4b9b-94b2-e0fb1276a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e021b10588334987892643b6c54284e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0. Loss: 0.5379652976989746. Accuracy: 65.64327485380117%. precision: 0. recall: 0.0. F1: 0.\n",
      "Iteration: 100. Loss: 0.48615002632141113. Accuracy: 65.64327485380117%. precision: 0. recall: 0.0. F1: 0.\n",
      "Iteration: 200. Loss: 0.5331752896308899. Accuracy: 65.64327485380117%. precision: 0. recall: 0.0. F1: 0.\n",
      "Iteration: 300. Loss: 0.28439924120903015. Accuracy: 65.64327485380117%. precision: 0. recall: 0.0. F1: 0.\n",
      "Iteration: 400. Loss: 0.9168493151664734. Accuracy: 65.64327485380117%. precision: 0. recall: 0.0. F1: 0.\n",
      "Iteration: 500. Loss: 0.6019229292869568. Accuracy: 65.5701754385965%. precision: 0.4000000059604645. recall: 0.0042553190141916275. F1: 0.008421052247285843.\n",
      "Iteration: 600. Loss: 0.6904578804969788. Accuracy: 65.71637426900585%. precision: 1.0. recall: 0.0021276595070958138. F1: 0.004246284253895283.\n",
      "Iteration: 700. Loss: 0.6620378494262695. Accuracy: 65.5701754385965%. precision: 0.4444444477558136. recall: 0.008510638028383255. F1: 0.016701459884643555.\n",
      "Iteration: 800. Loss: 0.5437301993370056. Accuracy: 65.5701754385965%. precision: 0.0. recall: 0.0. F1: 0.\n",
      "Iteration: 900. Loss: 0.5116795897483826. Accuracy: 65.64327485380117%. precision: 0. recall: 0.0. F1: 0.\n",
      "Iteration: 1000. Loss: 0.5172907710075378. Accuracy: 65.64327485380117%. precision: 0. recall: 0.0. F1: 0.\n",
      "Iteration: 1100. Loss: 0.7382712364196777. Accuracy: 65.42397660818713%. precision: 0.3333333432674408. recall: 0.006382978521287441. F1: 0.01252609584480524.\n",
      "Iteration: 1200. Loss: 0.6454617977142334. Accuracy: 65.71637426900585%. precision: 1.0. recall: 0.0021276595070958138. F1: 0.004246284253895283.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss() ## If required define your own criterion\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "optimizer_bert = torch.optim.AdamW(model_bert.parameters(), lr=2e-5, weight_decay=1e-1)\n",
    "\n",
    "\n",
    "max_epochs = 1\n",
    "i=0\n",
    "\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH: {}.\".format(epoch))\n",
    "    i=0\n",
    "    for batch, batch_aug in zip(training_loader,training_loader_aug): ## If you have a DataLoader()  object to get the data.\n",
    "        \n",
    "        data = batch[0]\n",
    "        targets = batch[1].cuda() ## assuming that data loader returns a tuple of data and its targets\n",
    "        if len(batch_aug[0].size())>2:\n",
    "            data_aug = batch_aug[0].view(batch_aug[0].size()[0],200).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_bert.zero_grad() \n",
    "        encoding = tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "        input_ids = encoding['input_ids'].cuda()\n",
    "        attention_mask = encoding['attention_mask'].cuda()\n",
    "        \n",
    "        outputs_bert = get_embedding(model_bert, input_ids, mask=attention_mask)        \n",
    "        outputs_bert = torch.mean(outputs_bert,dim=1)\n",
    "        outputs_bert = outputs_bert.view(outputs_bert.size()[0],4,192)\n",
    "        outputs_bert = torch.mean(outputs_bert,dim=1)\n",
    "        \n",
    "        inputs = torch.cat((outputs_bert, data_aug), dim = 1)\n",
    "        input_ids = torch.cat((input_ids, data_aug), dim=1)\n",
    "\n",
    "        # print(outputs_bert)\n",
    "        # outputs = F.log_softmax(outputs, dim=1)\n",
    "        # input_ids = torch.tensor(list(range(0,392)))\n",
    "        # if outputs_bert.size()[0]==3:\n",
    "        #     input_ids = torch.stack((input_ids,input_ids,input_ids), dim = 0).cuda()\n",
    "        # else:\n",
    "        #     input_ids = torch.stack((input_ids,input_ids,input_ids,input_ids,input_ids), dim = 0).cuda()\n",
    "        outputs = model.forward(input_ids)[0][:,1]\n",
    "        # _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # targets = targets.squeeze(1)\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_bert.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            tp = 0\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            for sent, sent_aug in zip(testing_loader, testing_loader_aug):\n",
    "                \n",
    "                label = sent[1].cuda()\n",
    "                sent = sent[0]\n",
    "                data_test_aug = sent_aug[0].cuda()\n",
    "                \n",
    "                if len(data_test_aug.size())>2:\n",
    "                    data_test_aug = data_test_aug.view(data_test_aug.size()[0],200).cuda()\n",
    "                    \n",
    "                # sent = sent.squeeze(1)\n",
    "                # if torch.cuda.is_available():\n",
    "                  # sent = sent.cuda()\n",
    "                  # label = label.cuda()\n",
    "                encoding = tokenizer.batch_encode_plus(sent, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "                input_ids = encoding['input_ids'].cuda()\n",
    "                attention_mask = encoding['attention_mask'].cuda()\n",
    "                outputs_bert = get_embedding(model_bert, input_ids, mask=attention_mask)        \n",
    "                outputs_bert = torch.mean(outputs_bert,dim=1)\n",
    "                outputs_bert = outputs_bert.view(outputs_bert.size()[0],4,192)\n",
    "                outputs_bert = torch.mean(outputs_bert,dim=1)\n",
    "                \n",
    "                inputs = torch.cat((outputs_bert, data_test_aug), dim = 1)\n",
    "                input_ids = torch.cat((input_ids, data_test_aug), dim=1)\n",
    "                # print(outputs_bert)\n",
    "                # outputs = F.log_softmax(outputs, dim=1)\n",
    "                # input_ids = torch.tensor(list(range(0,392)))\n",
    "                # if outputs_bert.size()[0]==3:\n",
    "                #     input_ids = torch.stack((input_ids,input_ids,input_ids), dim = 0).cuda()\n",
    "                # else:\n",
    "                #     input_ids = torch.stack((input_ids,input_ids,input_ids,input_ids,input_ids), dim = 0).cuda()\n",
    "                outputs = model.forward(input_ids)[0]\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "                tp += ((predicted.cpu() == label.cpu())&(label.cpu()==0)).sum()\n",
    "                fn += ((predicted.cpu() != label.cpu())&(label.cpu()==0)).sum()\n",
    "                fp += ((predicted.cpu() != label.cpu())&(label.cpu()==1)).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            if tp==0 and fp==0:\n",
    "                precision=0\n",
    "            else:\n",
    "                precision = tp/(tp+fp)\n",
    "            if tp==0 and fn==0:\n",
    "                recall=0\n",
    "            else:                \n",
    "                recall = tp/(tp+fn)\n",
    "            if precision == 0 and recall == 0:\n",
    "                F1 = 0\n",
    "            else:\n",
    "                F1=2*precision*recall/(precision+recall)\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%. precision: {}. recall: {}. F1: {}.'.format(i, loss.item(), accuracy, precision, recall, F1))\n",
    "        i+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2f68806-0a79-45e9-8840-53cc334e8a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c6b0602bf64081b0e6bd55d67b9bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'training_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c1335898bc45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH -- {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_loader' is not defined"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "model = model.train()\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        sent = sent.squeeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "          sent = sent.cuda()\n",
    "          label = label.cuda()\n",
    "        output = model.forward(sent)[0]\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for sent, label in testing_loader:\n",
    "                sent = sent.squeeze(0)\n",
    "                if torch.cuda.is_available():\n",
    "                  sent = sent.cuda()\n",
    "                  label = label.cuda()\n",
    "                output = model.forward(sent)[0]\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc6f4665-28c7-406d-a0a2-f58919bd83a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_jsons_aug = json.load(open('pah/data/relations_marked_train_aug.json'))\n",
    "len(train_jsons_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb21754-e9e0-4319-9a04-994ba4ff78eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_jsons_aug = json.load(open('pah/data/relations_marked_test_aug.json'))\n",
    "len(test_jsons_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e9dda52-1dec-44ce-977d-24658f62e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_LIST = [\".\",\",\",\":\", \"-LRB-\",\"-RRB-\",\"``\",\"\\\"\\\"\",\"''\",\",\",\"$\",\"#\",\"AFX\",\"CC\",\"CD\",\"DT\",\"EX\",\"FW\",\"HYPH\",\"IN\",\"JJ\",\"JJR\",\"JJS\",\"LS\",\"MD\",\"NIL\",\"NN\",\"NNP\",\"NNPS\",\"NNS\",\"PDT\",\"POS\",\"PRP\",\"PRP$\",\"RB\",\"RBR\",\"RBS\",\"RP\",\"SP\",\"SYM\",\"TO\",\"UH\",\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\",\"WDT\",\"WP\",\"WP$\",\"WRB\",\"ADD\",\"NFP\",\"GW\",\"XX\",\"BES\",\"HVS\",\"_SP\"]\n",
    "POS_LIST = [\"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CONJ\", \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \"PART\", \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\", \"SPACE\"]\n",
    "DEP_LIST = [\"acl\", \"acomp\", \"advcl\", \"advmod\", \"agent\", \"amod\", \"appos\", \"attr\", \"aux\", \"auxpass\", \"case\", \"cc\", \"ccomp\", \"compound\", \"conj\", \"cop\", \"csubj\", \"csubjpass\", \"dative\", \"dep\", \"det\", \"dobj\", \"expl\", \"intj\", \"mark\", \"meta\", \"neg\", \"nn\", \"npmod\", \"npadvmod\", \"nsubj\", \"nsubjpass\", \"nummod\",\"nmod\", \"oprd\", \"obj\", \"obl\", \"parataxis\", \"pcomp\",\"predet\", \"pobj\", \"poss\", \"preconj\", \"prep\", \"prt\", \"punct\",  \"quantmod\", \"relcl\", \"ROOT\", \"xcomp\"]\n",
    "NER_LIST = [\"PERSON\", \"NORP\", \"FAC\", \"ORG\", \"GPE\", \"LOC\", \"PRODUCT\", \"EVENT\", \"WORK_OF_ART\", \"LAW\", \"LANGUAGE\", \"DATE\", \"TIME\", \"PERCENT\", \"MONEY\", \"QUANTITY\", \"ORDINAL\", \"CARDINAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "813ca923-89a2-448a-928b-9c9d15825ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# nlp.tokenizer.vocab.morphology.tag_map\n",
    "pos_tags = {}\n",
    "for i,p in enumerate(TAG_LIST):\n",
    "    pos_tags[p] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd9c66f5-9593-4aa4-abc6-0b6567ab56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_tags = {}\n",
    "for i,p in enumerate(DEP_LIST):\n",
    "    dep_tags[p] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a1e10617-e66f-41a1-8b9f-4d1ec0780d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_jsons_aug)):\n",
    "    train_jsons_aug[i]['pos_tags_num'] = [pos_tags[t] for t in train_jsons_aug[i]['pos_tags']]\n",
    "    train_jsons_aug[i]['dep_tags_num'] = [dep_tags[t] for t in train_jsons_aug[i]['dep_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd9cd2dd-506a-456c-af3f-adbcda9e95a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_jsons_aug)):\n",
    "    test_jsons_aug[i]['pos_tags_num'] = [pos_tags[t] for t in test_jsons_aug[i]['pos_tags']]\n",
    "    test_jsons_aug[i]['dep_tags_num'] = [dep_tags[t] for t in test_jsons_aug[i]['dep_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2debb84b-5bed-4d48-970a-e3fcbf138683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rel</td>\n",
       "      <td>Methods In this double-blind , placebo-control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NotRel</td>\n",
       "      <td>In a preliminary study , the orally administer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rel</td>\n",
       "      <td>Methods In this double-blind , placebo-control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rel</td>\n",
       "      <td>Methods In this double-blind , placebo-control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rel</td>\n",
       "      <td>Methods In this double-blind , placebo-control...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                          utterance\n",
       "0     Rel  Methods In this double-blind , placebo-control...\n",
       "1  NotRel  In a preliminary study , the orally administer...\n",
       "2     Rel  Methods In this double-blind , placebo-control...\n",
       "3     Rel  Methods In this double-blind , placebo-control...\n",
       "4     Rel  Methods In this double-blind , placebo-control..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70e5e7e4-5a0e-4776-b76d-81d4316cb28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_aug(seq_2, var_dict, max_seq_length = 300, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True):\n",
    "    ## Tokenzine Input\n",
    "    tokens_a = seq_2\n",
    "\n",
    "    ## Truncate\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "    ## Initialize Tokens\n",
    "    tokens = []\n",
    "    if include_CLS_token:\n",
    "        tokens.append(tokenizer.cls_token)\n",
    "    ## Add Tokens and separators\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "\n",
    "    if include_SEP_token:\n",
    "        tokens.append(tokenizer.sep_token)\n",
    "\n",
    "    \n",
    "    input_ids = tokens_a\n",
    "    # input_ids = input_ids.squeeze(0)\n",
    "    ## Input Mask \n",
    "    input_mask = [1] * len(input_ids)\n",
    "    ## Zero-pad sequence lenght\n",
    "    if zero_pad:\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "    return torch.tensor(input_ids).unsqueeze(0), input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bcbb767d-41a2-4485-a8a7-ca37b74f7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "pos_tensor, _ = prepare_features_aug(train_df['pos_tags'][i], pos_tags, max_seq_length = 300, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "dep_tensor, _ = prepare_features_aug(train_df['dep_label'][i], dep_tags, max_seq_length = 300, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "tok_tensor,_= prepare_features(' '.join(train_df['tokens'][0]), max_seq_length = 300, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "ent_tensor,_ = prepare_features_aug(train_df['ent_type'][i], ent_dict, max_seq_length = 300, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2eabd830-6656-4114-9346-64b517111d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cat((pos_tensor, dep_tensor,tok_tensor), dim=1).size()\n",
    "# label\n",
    "tok_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e92b096-918c-4365-bd30-956c55123513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relations_Aug(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.tokens[index]\n",
    "        label = self.data.label[index]\n",
    "        pos_seq = self.data.pos_tags[index]\n",
    "        dep_seq = self.data.dep_label[index]\n",
    "        ent_seq = self.data.ent_type[index]\n",
    "        pos_tensor, _ = prepare_features_aug(pos_seq, pos_tags, max_seq_length = 100, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "        dep_tensor, _ = prepare_features_aug(dep_seq, dep_tags, max_seq_length = 100, \n",
    "                     zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "        tok_tensor,_= prepare_features(utterance, max_seq_length = 100, \n",
    "                     zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "        ent_tensor,_ = prepare_features_aug(ent_seq, ent_dict, max_seq_length = 100, \n",
    "             zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "        X = torch.cat((pos_tensor, dep_tensor, tok_tensor, ent_tensor), dim=1)\n",
    "        # y = label_to_ix[label]\n",
    "\n",
    "        return X #,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e33adc-1be8-478f-b1d2-c482fcb0052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(data):\n",
    "    df = pd.DataFrame({'tokens':[], 'pos_tags': [], 'dep_label': [], 'label': [], 'ent_type': []})\n",
    "    for index in tqdm_notebook(range(len(data))):\n",
    "        k = 0\n",
    "        ss1 = []\n",
    "        ent_types = []\n",
    "        for r in range(len(data[index]['relations'])):\n",
    "            k = 0\n",
    "            ss1 = []\n",
    "            label = data[index]['relations'][r]['type']\n",
    "            ent_types = []\n",
    "            # print(label)\n",
    "            while k<len(data[index]['tokens']):\n",
    "                if k == data[index]['entities'][data[index]['relations'][r]['head']]['start']:\n",
    "                    m = data[index]['entities'][data[index]['relations'][r]['head']]['end']\n",
    "                    ss1.append('[s1]')\n",
    "                    ss1.extend(data[index]['tokens'][k:m])\n",
    "                    ss1.append('[e1]')\n",
    "                    if k==m:\n",
    "                        m+=1\n",
    "                    for e in range(k,m):\n",
    "                        ent_types.append(data[index]['entities'][data[index]['relations'][r]['head']]['type'])\n",
    "                    k = m\n",
    "                elif k == data[index]['entities'][data[index]['relations'][r]['tail']]['start']:\n",
    "                    m = data[index]['entities'][data[index]['relations'][r]['tail']]['end']\n",
    "                    ss1.append('[s2]')\n",
    "                    ss1.extend(data[index]['tokens'][k:m])\n",
    "                    ss1.append('[e2]')\n",
    "                    if k==m:\n",
    "                        m+=1\n",
    "                    for e in range(k,m):\n",
    "                        ent_types.append(data[index]['entities'][data[index]['relations'][r]['tail']]['type'])\n",
    "                    k = m\n",
    "                else:\n",
    "                    ss1.append(data[index]['tokens'][k])\n",
    "                    ent_types.append('O')\n",
    "                    k+=1\n",
    "            df0 = pd.concat([pd.Series(' '.join(ss1)), pd.Series([[pos_tags[t] for t in data[index]['pos_tags']]]), \\\n",
    "                             pd.Series([[dep_tags[t] for t in data[index]['dep_label']]]), \n",
    "                            pd.Series([label]), pd.Series([[ent_dict[t] for t in ent_types]])], axis = 1)\n",
    "            df0.columns = df.columns\n",
    "            df = pd.concat([df, df0])\n",
    "            # df.loc[index,'tokens'] = ss1\n",
    "            # df.loc[index,'pos_tags'] = data[index]['pos_tags']\n",
    "            # df.loc[index,'dep_label'] = data[index]['dep_label']\n",
    "            # df.loc[i,'label'] = label\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bea1b88-c713-45b4-a93d-3ca773cdeb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77c653785ef40ce80316df0b0c5649c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1088 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4944f7100e044d2fac2cdd31ea25a99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = prepare_df(train_jsons_aug)\n",
    "test_df = prepare_df(test_jsons_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "435ceb6e-4399-4e8d-840e-50437eb1bd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>dep_label</th>\n",
       "      <th>label</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In ARIES-2 , a statistically significant impro...</td>\n",
       "      <td>[18, 26, 8, 14, 33, 19, 25, 18, 25, 18, 19, 25...</td>\n",
       "      <td>[43, 40, 45, 20, 3, 5, 31, 43, 40, 43, 5, 40, ...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>In ARIES-2 , a statistically significant impro...</td>\n",
       "      <td>[18, 26, 8, 14, 33, 19, 25, 18, 25, 18, 19, 25...</td>\n",
       "      <td>[43, 40, 45, 20, 3, 5, 31, 43, 40, 43, 5, 40, ...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The 6-minute walk distance is an independent p...</td>\n",
       "      <td>[14, 13, 25, 25, 46, 14, 19, 25, 18, 25, 18, 2...</td>\n",
       "      <td>[20, 33, 5, 30, 48, 20, 5, 7, 43, 40, 43, 40, ...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The 6-minute walk distance is an independent p...</td>\n",
       "      <td>[14, 13, 25, 25, 46, 14, 19, 25, 18, 25, 18, 2...</td>\n",
       "      <td>[20, 33, 5, 30, 48, 20, 5, 7, 43, 40, 43, 40, ...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>From these data , it appears that both the [s1...</td>\n",
       "      <td>[18, 14, 28, 8, 31, 46, 18, 12, 14, 26, 13, 19...</td>\n",
       "      <td>[43, 20, 40, 45, 30, 48, 24, 39, 20, 32, 5, 13...</td>\n",
       "      <td>Rel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 2, 2, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             tokens  \\\n",
       "0      0  In ARIES-2 , a statistically significant impro...   \n",
       "1      0  In ARIES-2 , a statistically significant impro...   \n",
       "2      0  The 6-minute walk distance is an independent p...   \n",
       "3      0  The 6-minute walk distance is an independent p...   \n",
       "4      0  From these data , it appears that both the [s1...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [18, 26, 8, 14, 33, 19, 25, 18, 25, 18, 19, 25...   \n",
       "1  [18, 26, 8, 14, 33, 19, 25, 18, 25, 18, 19, 25...   \n",
       "2  [14, 13, 25, 25, 46, 14, 19, 25, 18, 25, 18, 2...   \n",
       "3  [14, 13, 25, 25, 46, 14, 19, 25, 18, 25, 18, 2...   \n",
       "4  [18, 14, 28, 8, 31, 46, 18, 12, 14, 26, 13, 19...   \n",
       "\n",
       "                                           dep_label   label  \\\n",
       "0  [43, 40, 45, 20, 3, 5, 31, 43, 40, 43, 5, 40, ...  NotRel   \n",
       "1  [43, 40, 45, 20, 3, 5, 31, 43, 40, 43, 5, 40, ...  NotRel   \n",
       "2  [20, 33, 5, 30, 48, 20, 5, 7, 43, 40, 43, 40, ...  NotRel   \n",
       "3  [20, 33, 5, 30, 48, 20, 5, 7, 43, 40, 43, 40, ...  NotRel   \n",
       "4  [43, 20, 40, 45, 30, 48, 24, 39, 20, 32, 5, 13...     Rel   \n",
       "\n",
       "                                            ent_type  \n",
       "0  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  \n",
       "1  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  \n",
       "2  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  \n",
       "3  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  \n",
       "4  [25, 25, 25, 25, 25, 25, 25, 25, 25, 2, 2, 0, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7543d69-5f49-4c57-8b91-eefeb6bed163",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_dict = {}\n",
    "for i in range(len(train_jsons_aug)):\n",
    "    for ent in  train_jsons_aug[i]['entities']:\n",
    "        if ent['type'] not in ent_dict:\n",
    "            ent_dict[ent['type']] = len(ent_dict)\n",
    "            \n",
    "for i in range(len(test_jsons_aug)):\n",
    "    for ent in  test_jsons_aug[i]['entities']:\n",
    "        if ent['type'] not in ent_dict:\n",
    "            ent_dict[ent['type']] = len(ent_dict)\n",
    "            \n",
    "for i in range(len(inf_jsons_aug)):\n",
    "    for ent in  inf_jsons_aug[i]['entities']:\n",
    "        if ent['type'] not in ent_dict:\n",
    "            ent_dict[ent['type']] = len(ent_dict)\n",
    "ent_dict['O'] = len(ent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "816d5ab0-17b4-4e31-b492-610849de67c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drug': 0,\n",
       " 'reason': 1,\n",
       " '6mwd': 2,\n",
       " 'dosage': 3,\n",
       " 'duration': 4,\n",
       " 'cnt_patients': 5,\n",
       " 'fc': 6,\n",
       " 'death': 7,\n",
       " 'nt-probnp': 8,\n",
       " 'hospitalization': 9,\n",
       " 'progression': 10,\n",
       " 'prev_treat': 11,\n",
       " 'death_rate': 12,\n",
       " 'O': 13}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6192f3db-07fc-4576-bf24-59b349c7bffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>dep_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[In, a, preliminary, study, ,, the, orally, ad...</td>\n",
       "      <td>[IN, DT, JJ, NN, ,, DT, RB, VBN, JJ, NN, NN, N...</td>\n",
       "      <td>[prep, det, amod, pobj, punct, det, advmod, am...</td>\n",
       "      <td>NotRel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[Methods, In, this, double-blind, ,, placebo-c...</td>\n",
       "      <td>[NNS, IN, DT, NN, ,, JJ, NN, ,, PRP, RB, VBD, ...</td>\n",
       "      <td>[npadvmod, prep, det, pobj, punct, amod, pobj,...</td>\n",
       "      <td>NotRel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[Results, At, week, 16, 16, ,, patients, treat...</td>\n",
       "      <td>[NNS, IN, NN, CD, CD, ,, NNS, VBN, IN, NNP, VB...</td>\n",
       "      <td>[nsubj, prep, pobj, nummod, nummod, punct, nsu...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[Conclusions, The, endothelin-receptor, antago...</td>\n",
       "      <td>[NNS, DT, NN, NN, NNP, VBZ, JJ, IN, NNS, IN, J...</td>\n",
       "      <td>[nsubj, det, compound, compound, nsubj, ROOT, ...</td>\n",
       "      <td>NotRel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[Endothelin-receptor, antagonism, with, oral, ...</td>\n",
       "      <td>[NN, NN, IN, JJ, NNP, VBZ, DT, JJ, NN, IN, NN,...</td>\n",
       "      <td>[compound, nsubj, prep, amod, pobj, ROOT, det,...</td>\n",
       "      <td>NotRel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             tokens  \\\n",
       "0      0  [In, a, preliminary, study, ,, the, orally, ad...   \n",
       "1      0  [Methods, In, this, double-blind, ,, placebo-c...   \n",
       "2      0  [Results, At, week, 16, 16, ,, patients, treat...   \n",
       "3      0  [Conclusions, The, endothelin-receptor, antago...   \n",
       "4      0  [Endothelin-receptor, antagonism, with, oral, ...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [IN, DT, JJ, NN, ,, DT, RB, VBN, JJ, NN, NN, N...   \n",
       "1  [NNS, IN, DT, NN, ,, JJ, NN, ,, PRP, RB, VBD, ...   \n",
       "2  [NNS, IN, NN, CD, CD, ,, NNS, VBN, IN, NNP, VB...   \n",
       "3  [NNS, DT, NN, NN, NNP, VBZ, JJ, IN, NNS, IN, J...   \n",
       "4  [NN, NN, IN, JJ, NNP, VBZ, DT, JJ, NN, IN, NN,...   \n",
       "\n",
       "                                           dep_label   label  \n",
       "0  [prep, det, amod, pobj, punct, det, advmod, am...  NotRel  \n",
       "1  [npadvmod, prep, det, pobj, punct, amod, pobj,...  NotRel  \n",
       "2  [nsubj, prep, pobj, nummod, nummod, punct, nsu...     Rel  \n",
       "3  [nsubj, det, compound, compound, nsubj, ROOT, ...  NotRel  \n",
       "4  [compound, nsubj, prep, amod, pobj, ROOT, det,...  NotRel  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1da61f0f-3cd5-409b-935d-a9a0caee62cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[index]['relations'][1]['head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c97011d-0202-4d1b-97ae-0247fd82dcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'drug', 'start': 9, 'end': 10},\n",
       " {'type': 'reason', 'start': 21, 'end': 24},\n",
       " {'type': 'drug', 'start': 11, 'end': 12}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[index]['entities'][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e775d48-e7b7-4344-8065-6106511ea11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_aug = Relations_Aug(train_df)\n",
    "testing_set_aug = Relations_Aug(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe08e043-4d16-475f-ae96-4f011324a2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_aug.__getitem__(0)[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f0ccd54-083e-4e10-a4f6-b26acdcdebf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 600])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((pos_tensor, dep_tensor), dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02edaeed-6266-4480-a92d-9053595ffc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tensor.squeeze(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5133841e-6775-4cd0-82ea-031ca08f4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 1,\n",
    "          'drop_last': False,\n",
    "          # 'shuffle': True,\n",
    "          'num_workers': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34bf3194-dc5a-4ffb-9052-af05bcbc881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = torch.utils.data.sampler.BatchSampler(\n",
    "    torch.utils.data.sampler.RandomSampler(training_set_aug),\n",
    "    batch_size=1,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c714a3d6-47ea-464e-9253-2a2f6d23bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader_aug = DataLoader(training_set_aug, **params, sampler = sampler)\n",
    "testing_loader_aug = DataLoader(testing_set_aug, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74836fe9-da37-48ad-8585-96b265c0de54",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-61-c59562ad31c8>\", line 13, in __getitem__\n    zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n  File \"<ipython-input-17-db20c451c7f0>\", line 28, in prepare_features_aug\n    input_ids.append(0)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\", line 2878, in append\n    to_concat, ignore_index=ignore_index, verify_integrity=verify_integrity\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\", line 304, in concat\n    sort=sort,\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\", line 384, in __init__\n    raise TypeError(msg)\nTypeError: cannot concatenate object of type '<class 'int'>'; only Series and DataFrame objs are valid\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-8805882df1b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_loader_aug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-61-c59562ad31c8>\", line 13, in __getitem__\n    zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n  File \"<ipython-input-17-db20c451c7f0>\", line 28, in prepare_features_aug\n    input_ids.append(0)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\", line 2878, in append\n    to_concat, ignore_index=ignore_index, verify_integrity=verify_integrity\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\", line 304, in concat\n    sort=sort,\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\", line 384, in __init__\n    raise TypeError(msg)\nTypeError: cannot concatenate object of type '<class 'int'>'; only Series and DataFrame objs are valid\n"
     ]
    }
   ],
   "source": [
    "for data in training_loader_aug:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18574765-ecc9-41c2-987b-7d6d9cac9743",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-05\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "782fe924-bc52-4171-896d-6b71687f4813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 400]) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "## Test Forward Pass\n",
    "inp = training_set_aug.__getitem__(0)[0].cuda()\n",
    "output = model(inp)[0]\n",
    "print(inp.shape, output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3a8ce-848d-4159-aaca-2ff577dc96f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b8a2185a9f4422bdfb8d6662f4fc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-38-76a41a839139>\", line 13, in __getitem__\n    zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n  File \"<ipython-input-17-db20c451c7f0>\", line 28, in prepare_features_aug\n    input_ids.append(0)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\", line 2878, in append\n    to_concat, ignore_index=ignore_index, verify_integrity=verify_integrity\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\", line 304, in concat\n    sort=sort,\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\", line 384, in __init__\n    raise TypeError(msg)\nTypeError: cannot concatenate object of type '<class 'int'>'; only Series and DataFrame objs are valid\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-80b809c603d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH -- {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-38-76a41a839139>\", line 13, in __getitem__\n    zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n  File \"<ipython-input-17-db20c451c7f0>\", line 28, in prepare_features_aug\n    input_ids.append(0)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\", line 2878, in append\n    to_concat, ignore_index=ignore_index, verify_integrity=verify_integrity\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\", line 304, in concat\n    sort=sort,\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\", line 384, in __init__\n    raise TypeError(msg)\nTypeError: cannot concatenate object of type '<class 'int'>'; only Series and DataFrame objs are valid\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 20\n",
    "model = model.train()\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(training_loader_aug):\n",
    "        optimizer.zero_grad()\n",
    "        sent = sent.squeeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "          sent = sent.cuda()\n",
    "          label = label.cuda()\n",
    "        output = model.forward(sent)[0]\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for sent, label in testing_loader_aug:\n",
    "                sent = sent.squeeze(0)\n",
    "                if torch.cuda.is_available():\n",
    "                  sent = sent.cuda()\n",
    "                  label = label.cuda()\n",
    "                output = model.forward(sent)[0]\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "201a48ca-a5bd-48d5-9434-430b4a750ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in training_loader_aug:\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b0990df-79ce-4bbc-bcdc-e05e0d4f8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_biobert_vars_71'+ str(uuid4())+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e749d54d-b1b1-4747-b7c0-b5ce2ace8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_4_varsbfdfa1d5-0f06-4aa5-89db-c9f541216795.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d47cc34-1646-4a5b-904c-abc5af1de36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c94c32d-1999-4f1f-862b-736e1384a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(data,index):\n",
    "    model.eval()\n",
    "    utterance = ' '.join(data.tokens[index])\n",
    "    pos_seq = data.pos_tags[index]\n",
    "    dep_seq = data.dep_label[index]\n",
    "    ent_seq = data.ent_type[index]\n",
    "    pos_tensor, _ = prepare_features_aug(pos_seq, pos_tags, max_seq_length = 100, \n",
    "         zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "    dep_tensor, _ = prepare_features_aug(dep_seq, dep_tags, max_seq_length = 100, \n",
    "                 zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "    tok_tensor,_= prepare_features(utterance, max_seq_length = 100, \n",
    "                 zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "    ent_tensor,_ = prepare_features_aug(ent_seq, ent_dict, max_seq_length = 100, \n",
    "         zero_pad = True, include_CLS_token = True, include_SEP_token = True)\n",
    "    X = torch.cat((pos_tensor, dep_tensor, tok_tensor, ent_tensor), dim=1)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        X = X.cuda()\n",
    "    output = model(X)[0]\n",
    "    _, pred_label = torch.max(output.data, 1)\n",
    "    prediction=list(label_to_ix.keys())[pred_label]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28058196-0de1-43fc-939a-563eb934cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_jsons_aug = json.load(open('pah/data/articles_inf_aa_aug.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2f3358d-9c2d-4d26-ba6f-ac7d651e8209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'duration', 'start': 7, 'end': 9}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_jsons_aug[10]['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c77fa384-60df-4593-85d3-1a8c92a82df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35564db1f5384ca89b31e7689a4af9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>dep_label</th>\n",
       "      <th>label</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Comparison of hemodynamic parameters in treatm...</td>\n",
       "      <td>[25, 18, 19, 28, 18, 19, 12, 42, 28, 18, 19, 1...</td>\n",
       "      <td>[48, 43, 5, 40, 43, 5, 11, 14, 40, 43, 5, 5, 4...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Comparison of hemodynamic parameters in treatm...</td>\n",
       "      <td>[25, 18, 19, 28, 18, 19, 12, 42, 28, 18, 19, 1...</td>\n",
       "      <td>[48, 43, 5, 40, 43, 5, 11, 14, 40, 43, 5, 5, 4...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>[25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...</td>\n",
       "      <td>[13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>[25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...</td>\n",
       "      <td>[13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>[25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...</td>\n",
       "      <td>[13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             tokens  \\\n",
       "0      0  Comparison of hemodynamic parameters in treatm...   \n",
       "1      0  Comparison of hemodynamic parameters in treatm...   \n",
       "2      0  E-mail address : nazzareno.galie @ unibo.it BA...   \n",
       "3      0  E-mail address : nazzareno.galie @ unibo.it BA...   \n",
       "4      0  E-mail address : nazzareno.galie @ unibo.it BA...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [25, 18, 19, 28, 18, 19, 12, 42, 28, 18, 19, 1...   \n",
       "1  [25, 18, 19, 28, 18, 19, 12, 42, 28, 18, 19, 1...   \n",
       "2  [25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...   \n",
       "3  [25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...   \n",
       "4  [25, 25, 2, 25, 18, 26, 26, 2, 25, 18, 19, 19,...   \n",
       "\n",
       "                                           dep_label   label  \\\n",
       "0  [48, 43, 5, 40, 43, 5, 11, 14, 40, 43, 5, 5, 4...  NotRel   \n",
       "1  [48, 43, 5, 40, 43, 5, 11, 14, 40, 43, 5, 5, 4...  NotRel   \n",
       "2  [13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...  NotRel   \n",
       "3  [13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...  NotRel   \n",
       "4  [13, 48, 45, 19, 45, 13, 48, 45, 48, 43, 5, 5,...  NotRel   \n",
       "\n",
       "                                            ent_type  \n",
       "0  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5,...  \n",
       "1  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 5, 5,...  \n",
       "2  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  \n",
       "3  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  \n",
       "4  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = prepare_df(inf_jsons_aug)\n",
    "inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2eca3b83-805b-41f7-a8e5-cd667df245b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df = inf_df[['tokens']]\n",
    "inf_df.columns = ['utterance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9393c533-ec01-4d43-9967-5ea4a50c6716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d859cacd67340dab6eb13f2334396a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b478d4be6860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minf_rel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minf_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minf_rel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minf_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-bdd65da86c19>\u001b[0m in \u001b[0;36mget_reply\u001b[0;34m(test_df, index)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-4604dadbd643>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#                             attention_mask=mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlinear1_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## extract the 1st token's embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# last_hidden_state_cls = sequence_output[:,0,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-4604dadbd643>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#                             attention_mask=mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlinear1_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## extract the 1st token's embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# last_hidden_state_cls = sequence_output[:,0,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 1 with size 3"
     ]
    }
   ],
   "source": [
    "inf_rel = []\n",
    "for i in tqdm_notebook(range(inf_df.shape[0])):\n",
    "    inf_rel.append(get_reply(inf_df, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28f85dd2-fcdf-4140-90e6-c4e50e377d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57733"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inf_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f75491c-ef50-4236-ae3e-e8d2a1beff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_rel = pred\n",
    "inf_rel_df = pd.DataFrame(inf_rel)\n",
    "inf_rel_df.columns = ['Relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa8c9402-de44-4b65-a110-440cdddea495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotRel    54145\n",
       "Rel       20075\n",
       "Name: Relation, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_rel_df.Relation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f2f013b-14e6-43d0-8065-a878839b3681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "      <th>Relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comparison of hemodynamic parameters in treatm...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>NotRel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comparison of hemodynamic parameters in treatm...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>NotRel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance   label Relation\n",
       "0  Comparison of hemodynamic parameters in treatm...  NotRel   NotRel\n",
       "1  Comparison of hemodynamic parameters in treatm...  NotRel      Rel\n",
       "2  E-mail address : nazzareno.galie @ unibo.it BA...  NotRel      Rel\n",
       "3  E-mail address : nazzareno.galie @ unibo.it BA...  NotRel      Rel\n",
       "4  E-mail address : nazzareno.galie @ unibo.it BA...  NotRel   NotRel"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = pd.concat([inf_df, inf_rel_df], axis = 1)\n",
    "inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e763b5e4-a020-49e6-bfd5-88ebd6c036c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>dep_label</th>\n",
       "      <th>label</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>Relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS, :, Patients, with, [s1], PAH, [e1], ...</td>\n",
       "      <td>[NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...</td>\n",
       "      <td>[ROOT, punct, appos, prep, pobj, nsubj, relcl,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, reason, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS, :, Patients, with, [s1], PAH, [e1], ...</td>\n",
       "      <td>[NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...</td>\n",
       "      <td>[ROOT, punct, appos, prep, pobj, nsubj, relcl,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, reason, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS, :, Patients, with, PAH, who, were, t...</td>\n",
       "      <td>[NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...</td>\n",
       "      <td>[ROOT, punct, appos, prep, pobj, nsubj, relcl,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, drug, O, ...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS, :, Patients, with, [s2], PAH, [e2], ...</td>\n",
       "      <td>[NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...</td>\n",
       "      <td>[ROOT, punct, appos, prep, pobj, nsubj, relcl,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, reason, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>[METHODS, :, Patients, with, [s2], PAH, [e2], ...</td>\n",
       "      <td>[NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...</td>\n",
       "      <td>[ROOT, punct, appos, prep, pobj, nsubj, relcl,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, reason, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74181</th>\n",
       "      <td>0</td>\n",
       "      <td>[In, this, trial, ,, a, total, of, 185, PAH, p...</td>\n",
       "      <td>[IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...</td>\n",
       "      <td>[prep, det, pobj, punct, det, nsubjpass, prep,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74184</th>\n",
       "      <td>0</td>\n",
       "      <td>[In, this, trial, ,, a, total, of, 185, PAH, p...</td>\n",
       "      <td>[IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...</td>\n",
       "      <td>[prep, det, pobj, punct, det, nsubjpass, prep,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74185</th>\n",
       "      <td>0</td>\n",
       "      <td>[In, this, trial, ,, a, total, of, 185, PAH, p...</td>\n",
       "      <td>[IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...</td>\n",
       "      <td>[prep, det, pobj, punct, det, nsubjpass, prep,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74188</th>\n",
       "      <td>0</td>\n",
       "      <td>[In, this, trial, ,, a, total, of, 185, PAH, p...</td>\n",
       "      <td>[IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...</td>\n",
       "      <td>[prep, det, pobj, punct, det, nsubjpass, prep,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74189</th>\n",
       "      <td>0</td>\n",
       "      <td>[In, this, trial, ,, a, total, of, 185, PAH, p...</td>\n",
       "      <td>[IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...</td>\n",
       "      <td>[prep, det, pobj, punct, det, nsubjpass, prep,...</td>\n",
       "      <td>NotRel</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15062 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                             tokens  \\\n",
       "9          0  [METHODS, :, Patients, with, [s1], PAH, [e1], ...   \n",
       "10         0  [METHODS, :, Patients, with, [s1], PAH, [e1], ...   \n",
       "13         0  [METHODS, :, Patients, with, PAH, who, were, t...   \n",
       "14         0  [METHODS, :, Patients, with, [s2], PAH, [e2], ...   \n",
       "17         0  [METHODS, :, Patients, with, [s2], PAH, [e2], ...   \n",
       "...      ...                                                ...   \n",
       "74181      0  [In, this, trial, ,, a, total, of, 185, PAH, p...   \n",
       "74184      0  [In, this, trial, ,, a, total, of, 185, PAH, p...   \n",
       "74185      0  [In, this, trial, ,, a, total, of, 185, PAH, p...   \n",
       "74188      0  [In, this, trial, ,, a, total, of, 185, PAH, p...   \n",
       "74189      0  [In, this, trial, ,, a, total, of, 185, PAH, p...   \n",
       "\n",
       "                                                pos_tags  \\\n",
       "9      [NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...   \n",
       "10     [NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...   \n",
       "13     [NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...   \n",
       "14     [NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...   \n",
       "17     [NNP, :, NNS, IN, NNP, WP, VBD, NN, JJ, CC, VB...   \n",
       "...                                                  ...   \n",
       "74181  [IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...   \n",
       "74184  [IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...   \n",
       "74185  [IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...   \n",
       "74188  [IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...   \n",
       "74189  [IN, DT, NN, ,, DT, NN, IN, CD, NNP, NNS, IN, ...   \n",
       "\n",
       "                                               dep_label   label  \\\n",
       "9      [ROOT, punct, appos, prep, pobj, nsubj, relcl,...  NotRel   \n",
       "10     [ROOT, punct, appos, prep, pobj, nsubj, relcl,...  NotRel   \n",
       "13     [ROOT, punct, appos, prep, pobj, nsubj, relcl,...  NotRel   \n",
       "14     [ROOT, punct, appos, prep, pobj, nsubj, relcl,...  NotRel   \n",
       "17     [ROOT, punct, appos, prep, pobj, nsubj, relcl,...  NotRel   \n",
       "...                                                  ...     ...   \n",
       "74181  [prep, det, pobj, punct, det, nsubjpass, prep,...  NotRel   \n",
       "74184  [prep, det, pobj, punct, det, nsubjpass, prep,...  NotRel   \n",
       "74185  [prep, det, pobj, punct, det, nsubjpass, prep,...  NotRel   \n",
       "74188  [prep, det, pobj, punct, det, nsubjpass, prep,...  NotRel   \n",
       "74189  [prep, det, pobj, punct, det, nsubjpass, prep,...  NotRel   \n",
       "\n",
       "                                                ent_type Relation  \n",
       "9      [O, O, O, O, reason, O, O, O, O, O, O, O, O, O...      Rel  \n",
       "10     [O, O, O, O, reason, O, O, O, O, O, O, O, O, O...      Rel  \n",
       "13     [O, O, O, O, O, O, O, O, O, O, O, O, drug, O, ...      Rel  \n",
       "14     [O, O, O, O, reason, O, O, O, O, O, O, O, O, O...      Rel  \n",
       "17     [O, O, O, O, reason, O, O, O, O, O, O, O, O, O...      Rel  \n",
       "...                                                  ...      ...  \n",
       "74181  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...      Rel  \n",
       "74184  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...      Rel  \n",
       "74185  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...      Rel  \n",
       "74188  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...      Rel  \n",
       "74189  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...      Rel  \n",
       "\n",
       "[15062 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df[inf_df['Relation']=='Rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aeaa8ef6-66d1-430a-bfe3-2e5b14856392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotRel    932\n",
       "Rel       179\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "927faeed-4767-4489-b4c6-e61cb35532b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df[['utterance', 'Relation']].to_csv('inf_model_biobert_best.csv')\n",
    "inf_df[200:250].to_csv('inf_model_bb_best_sample_50.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "90fd2aac-4c8f-4a7f-b43f-e02598ee27fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ss1</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>T</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NotRel</td>\n",
       "      <td>we hypothesized [s1] milrinone [e1] milrinone ...</td>\n",
       "      <td>Drug</td>\n",
       "      <td>Route</td>\n",
       "      <td>T_121</td>\n",
       "      <td>T_1170</td>\n",
       "      <td>F_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NotRel</td>\n",
       "      <td>we hypothesized [s1] milrinone [e1] [s2] inhal...</td>\n",
       "      <td>Drug</td>\n",
       "      <td>Route</td>\n",
       "      <td>T_121</td>\n",
       "      <td>T_1254</td>\n",
       "      <td>F_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NotRel</td>\n",
       "      <td>we hypothesized [s1] milrinone [e1] [s2] prost...</td>\n",
       "      <td>Drug</td>\n",
       "      <td>Drug</td>\n",
       "      <td>T_121</td>\n",
       "      <td>T_1262</td>\n",
       "      <td>F_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NotRel</td>\n",
       "      <td>we hypothesized [s1] inhaled [e1] [s2] prostac...</td>\n",
       "      <td>Route</td>\n",
       "      <td>Drug</td>\n",
       "      <td>T_1170</td>\n",
       "      <td>T_1262</td>\n",
       "      <td>F_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NotRel</td>\n",
       "      <td>we hypothesized that [s1] inhaled [e1] , an ad...</td>\n",
       "      <td>Route</td>\n",
       "      <td>Drug</td>\n",
       "      <td>T_1254</td>\n",
       "      <td>T_1262</td>\n",
       "      <td>F_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                                ss1   tag1   tag2  \\\n",
       "0  NotRel  we hypothesized [s1] milrinone [e1] milrinone ...   Drug  Route   \n",
       "1  NotRel  we hypothesized [s1] milrinone [e1] [s2] inhal...   Drug  Route   \n",
       "2  NotRel  we hypothesized [s1] milrinone [e1] [s2] prost...   Drug   Drug   \n",
       "3  NotRel  we hypothesized [s1] inhaled [e1] [s2] prostac...  Route   Drug   \n",
       "4  NotRel  we hypothesized that [s1] inhaled [e1] , an ad...  Route   Drug   \n",
       "\n",
       "        T       D    F  \n",
       "0   T_121  T_1170  F_1  \n",
       "1   T_121  T_1254  F_1  \n",
       "2   T_121  T_1262  F_1  \n",
       "3  T_1170  T_1262  F_1  \n",
       "4  T_1254  T_1262  F_1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fs = pd.read_csv('ClinicalTransformerRelationExtraction/CRE_PAH/v7/test_fs.tsv', delimiter = '\\t', header = None)\n",
    "test_fs.columns = ['label','ss1','tag1','tag2','T','D','F']\n",
    "test_fs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "75910cdc-9530-4946-89c3-e70f24cfbe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>utterance</th>\n",
       "      <th>Relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Comparison of hemodynamic parameters in treatm...</td>\n",
       "      <td>NotRel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparison of hemodynamic parameters in treatm...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>Rel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E-mail address : nazzareno.galie @ unibo.it BA...</td>\n",
       "      <td>NotRel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          utterance Relation\n",
       "0           0  Comparison of hemodynamic parameters in treatm...   NotRel\n",
       "1           1  Comparison of hemodynamic parameters in treatm...      Rel\n",
       "2           2  E-mail address : nazzareno.galie @ unibo.it BA...      Rel\n",
       "3           3  E-mail address : nazzareno.galie @ unibo.it BA...      Rel\n",
       "4           4  E-mail address : nazzareno.galie @ unibo.it BA...   NotRel"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = pd.read_csv('inf_model_biobert_best.csv')\n",
    "inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b4e07f85-5566-42b8-b621-d75984c2d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df.sample(150).to_csv('inf_model_biobert_best_sample_150.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "299ba14e-9d9e-4092-9058-236e667f553a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        comparisonofhemodynamicparametersintreatment-n...\n",
       "1        comparisonofhemodynamicparametersintreatment-n...\n",
       "2        e-mailaddress:nazzareno.galie@unibo.itbackgrou...\n",
       "3        e-mailaddress:nazzareno.galie@unibo.itbackgrou...\n",
       "4        e-mailaddress:nazzareno.galie@unibo.itbackgrou...\n",
       "                               ...                        \n",
       "74215    the[s1]2-and[s2]48-week[e2]results[s1]uggestth...\n",
       "74216    inflammationalsohasanincreasinglyrecognisedrol...\n",
       "74217    inflammationalsohasanincreasinglyrecognisedrol...\n",
       "74218    severalformsof[s1]pah[e1],includingidiopathicp...\n",
       "74219    severalformsof[s2]pah[e2],includingidiopathicp...\n",
       "Name: utterance, Length: 74220, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df['utterance'] = inf_df['utterance'].str.lower().str.replace(' ','')\n",
    "inf_df.utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "154b2ccd-301f-4846-a42f-c8df5f841370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         wehypothesized[s1]milrinone[e1]milrinone,anade...\n",
       "1         wehypothesized[s1]milrinone[e1][s2]inhaled[e2]...\n",
       "2         wehypothesized[s1]milrinone[e1][s2]prostacycli...\n",
       "3         wehypothesized[s1]inhaled[e1][s2]prostacyclin[...\n",
       "4         wehypothesizedthat[s1]inhaled[e1],anadenosine-...\n",
       "                                ...                        \n",
       "149981    tablev[s1]gelatin[e1][s2]3%[e2]invivooraldtcou...\n",
       "149982    tablevshows[s1]3%[e1]invivooraldtcouldbearrang...\n",
       "149983    [s1]sublingual[e1]meanplasmaconcentrationversu...\n",
       "149984    [s1]sublingual[e1][s2]oral[e2]plasmaconcentrat...\n",
       "149985    [s1]lyophylizedsublingual[e1]plasmaconcentrati...\n",
       "Name: ss1, Length: 149986, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fs['ss1'] = test_fs['ss1'].str.lower().str.replace(' ','')\n",
    "test_fs.merge(inf_df, left_on = 'ss1', right_on = 'utterance').shape"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
