{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7402d4ca-ce8e-466a-8407-bcfd284dfc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !git clone https://github.com/uf-hobi-informatics-lab/ClinicalTransformerRelationExtraction\n",
    "# !pip install -r ClinicalTransformerRelationExtraction/requirements.txt\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# --pretrained_model microsoft/deberta-base \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "925e9af7-498e-429f-b883-7ede1d73fd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHELL=/bin/bash\n",
      "NVIDIA_VISIBLE_DEVICES=all\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/_sagemaker-instance-credentials/a028f70afffe2e512050cbca6a6d34b6382542d1381dedd67bbb5ef26745f5b7\n",
      "PYTHONNOUSERSITE=0\n",
      "HOSTNAME=datascience-1-0-ml-g4dn-xlarge-94fad2f4401e538ca1255dfa1e84\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE=0\n",
      "SAGEMAKER_LOG_FILE=/var/log/studio/kernel_gateway.log\n",
      "AWS_DEFAULT_REGION=us-east-1\n",
      "KERNEL_WORKING_PATH=\n",
      "KERNEL_LAUNCH_TIMEOUT=40\n",
      "AWS_REGION=us-east-1\n",
      "PWD=/root\n",
      "REGION_NAME=us-east-1\n",
      "AWS_INTERNAL_IMAGE_OWNER=Studio\n",
      "HOME=/root\n",
      "LANG=C.UTF-8\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "CLICOLOR=1\n",
      "JPY_PARENT_PID=9\n",
      "TERM=xterm-color\n",
      "GIT_PAGER=cat\n",
      "CONDA_MD5=d63adf39f2c220950a063e0529d4ff74\n",
      "AWS_ACCOUNT_ID=713511755762\n",
      "SHLVL=0\n",
      "PAGER=cat\n",
      "CONDA_DIR=/opt/.sagemakerinternal/conda\n",
      "KERNEL_GATEWAY=1\n",
      "JUPYTER_PATH=/opt/conda/share/jupyter/\n",
      "MPLBACKEND=module://ipykernel.pylab.backend_inline\n",
      "CONDA_VERSION=py38_4.8.3\n",
      "LC_ALL=C.UTF-8\n",
      "PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin\n",
      "DEBIAN_FRONTEND=noninteractive\n",
      "_=/usr/bin/env\n",
      "data_dir=ClinicalTransformerRelationExtraction/CRE_PAH/\n",
      "SHELL=/bin/bash\n",
      "NVIDIA_VISIBLE_DEVICES=all\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/_sagemaker-instance-credentials/a028f70afffe2e512050cbca6a6d34b6382542d1381dedd67bbb5ef26745f5b7\n",
      "PYTHONNOUSERSITE=0\n",
      "HOSTNAME=datascience-1-0-ml-g4dn-xlarge-94fad2f4401e538ca1255dfa1e84\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE=0\n",
      "SAGEMAKER_LOG_FILE=/var/log/studio/kernel_gateway.log\n",
      "AWS_DEFAULT_REGION=us-east-1\n",
      "KERNEL_WORKING_PATH=\n",
      "KERNEL_LAUNCH_TIMEOUT=40\n",
      "AWS_REGION=us-east-1\n",
      "PWD=/root\n",
      "REGION_NAME=us-east-1\n",
      "AWS_INTERNAL_IMAGE_OWNER=Studio\n",
      "HOME=/root\n",
      "LANG=C.UTF-8\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "CLICOLOR=1\n",
      "JPY_PARENT_PID=9\n",
      "TERM=xterm-color\n",
      "GIT_PAGER=cat\n",
      "CONDA_MD5=d63adf39f2c220950a063e0529d4ff74\n",
      "AWS_ACCOUNT_ID=713511755762\n",
      "SHLVL=0\n",
      "PAGER=cat\n",
      "CONDA_DIR=/opt/.sagemakerinternal/conda\n",
      "KERNEL_GATEWAY=1\n",
      "JUPYTER_PATH=/opt/conda/share/jupyter/\n",
      "MPLBACKEND=module://ipykernel.pylab.backend_inline\n",
      "CONDA_VERSION=py38_4.8.3\n",
      "LC_ALL=C.UTF-8\n",
      "PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin\n",
      "DEBIAN_FRONTEND=noninteractive\n",
      "_=/usr/bin/env\n",
      "nmd=ClinicalTransformerRelationExtraction/roberta_re\n",
      "SHELL=/bin/bash\n",
      "NVIDIA_VISIBLE_DEVICES=all\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/_sagemaker-instance-credentials/a028f70afffe2e512050cbca6a6d34b6382542d1381dedd67bbb5ef26745f5b7\n",
      "PYTHONNOUSERSITE=0\n",
      "HOSTNAME=datascience-1-0-ml-g4dn-xlarge-94fad2f4401e538ca1255dfa1e84\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE=0\n",
      "SAGEMAKER_LOG_FILE=/var/log/studio/kernel_gateway.log\n",
      "AWS_DEFAULT_REGION=us-east-1\n",
      "KERNEL_WORKING_PATH=\n",
      "KERNEL_LAUNCH_TIMEOUT=40\n",
      "AWS_REGION=us-east-1\n",
      "PWD=/root\n",
      "REGION_NAME=us-east-1\n",
      "AWS_INTERNAL_IMAGE_OWNER=Studio\n",
      "HOME=/root\n",
      "LANG=C.UTF-8\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "CLICOLOR=1\n",
      "JPY_PARENT_PID=9\n",
      "TERM=xterm-color\n",
      "GIT_PAGER=cat\n",
      "CONDA_MD5=d63adf39f2c220950a063e0529d4ff74\n",
      "AWS_ACCOUNT_ID=713511755762\n",
      "SHLVL=0\n",
      "PAGER=cat\n",
      "CONDA_DIR=/opt/.sagemakerinternal/conda\n",
      "KERNEL_GATEWAY=1\n",
      "JUPYTER_PATH=/opt/conda/share/jupyter/\n",
      "MPLBACKEND=module://ipykernel.pylab.backend_inline\n",
      "CONDA_VERSION=py38_4.8.3\n",
      "LC_ALL=C.UTF-8\n",
      "PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin\n",
      "DEBIAN_FRONTEND=noninteractive\n",
      "_=/usr/bin/env\n",
      "pof=predictions.txt\n",
      "SHELL=/bin/bash\n",
      "NVIDIA_VISIBLE_DEVICES=all\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/_sagemaker-instance-credentials/a028f70afffe2e512050cbca6a6d34b6382542d1381dedd67bbb5ef26745f5b7\n",
      "PYTHONNOUSERSITE=0\n",
      "HOSTNAME=datascience-1-0-ml-g4dn-xlarge-94fad2f4401e538ca1255dfa1e84\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE=0\n",
      "SAGEMAKER_LOG_FILE=/var/log/studio/kernel_gateway.log\n",
      "AWS_DEFAULT_REGION=us-east-1\n",
      "KERNEL_WORKING_PATH=\n",
      "KERNEL_LAUNCH_TIMEOUT=40\n",
      "AWS_REGION=us-east-1\n",
      "PWD=/root\n",
      "REGION_NAME=us-east-1\n",
      "AWS_INTERNAL_IMAGE_OWNER=Studio\n",
      "HOME=/root\n",
      "LANG=C.UTF-8\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "CLICOLOR=1\n",
      "JPY_PARENT_PID=9\n",
      "TERM=xterm-color\n",
      "GIT_PAGER=cat\n",
      "CONDA_MD5=d63adf39f2c220950a063e0529d4ff74\n",
      "AWS_ACCOUNT_ID=713511755762\n",
      "SHLVL=0\n",
      "PAGER=cat\n",
      "CONDA_DIR=/opt/.sagemakerinternal/conda\n",
      "KERNEL_GATEWAY=1\n",
      "JUPYTER_PATH=/opt/conda/share/jupyter/\n",
      "MPLBACKEND=module://ipykernel.pylab.backend_inline\n",
      "CONDA_VERSION=py38_4.8.3\n",
      "LC_ALL=C.UTF-8\n",
      "PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin\n",
      "DEBIAN_FRONTEND=noninteractive\n",
      "_=/usr/bin/env\n",
      "log=log.txt\n",
      "2022-12-18 05:35:29.584069: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 05:35:29.727301: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-18 05:35:30.416094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 05:35:30.416193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 05:35:30.416208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "ClinicalTransformerRelationExtraction/src/relation_extraction.py:35: UserWarning: You set the eval mode so we expect max_num_checkpoints large than 0 so we set it to 1.\n",
      "  warnings.warn(\"You set the eval mode so we expect max_num_checkpoints large than 0 so we set it to 1.\")\n",
      "2022-12-18 05:35:31 - Transformer_Relation_Extraction - INFO - Init new model...\n",
      "2022-12-18 05:35:31 - Transformer_Relation_Extraction - INFO - label to index:\n",
      "{'NotRel': 0, 'Rel': 1}\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RoBERTaForRelationIdentification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RoBERTaForRelationIdentification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RoBERTaForRelationIdentification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RoBERTaForRelationIdentification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['base_classifier.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'base_classifier.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-12-18 05:35:37 - Transformer_Relation_Extraction - INFO - data loader info: key: data_dir; val: ClinicalTransformerRelationExtraction/CRE_PAH/v7\n",
      "key: tokenizer; val: PreTrainedTokenizer(name_or_path='roberta-base', vocab_size=50265, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)})\n",
      "key: max_seq_len; val: 256\n",
      "key: num_core; val: 1\n",
      "key: header; val: True\n",
      "key: tokenizer_type; val: roberta\n",
      "key: total_special_token_num; val: 3\n",
      "2022-12-18 05:35:37 - Transformer_Relation_Extraction - INFO - load train data from cached file: ClinicalTransformerRelationExtraction/CRE_PAH/v7/cached_roberta_0_256_roberta-base_train.pkl\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/data/processors/glue.py:66: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - Feature1:\n",
      "InputFeatures(input_ids=[0, 366, 1342, 260, 34, 57, 2343, 7, 28, 55, 2375, 87, 26231, 11, 4881, 34049, 30404, 36, 5931, 4839, 1164, 11, 50265, 642, 922, 43462, 39929, 2617, 30960, 479, 50266, 134, 20, 1262, 34, 555, 10, 2526, 5804, 13, 10439, 7, 30389, 3814, 623, 1309, 6481, 36, 13387, 4839, 333, 112, 34049, 30960, 4, 176, 6, 246, 20, 304, 9, 253, 15244, 2614, 33915, 9876, 6643, 12, 295, 1952, 7, 3951, 333, 112, 34049, 39929, 2617, 30960, 34, 669, 7, 41, 1374, 2782, 7967, 11, 42, 333, 4, 306, 4701, 876, 808, 13310, 12, 38838, 34049, 30960, 36, 208, 30638, 4839, 16, 2325, 11, 333, 195, 9, 5, 595, 13387, 1380, 118, 43251, 11582, 10172, 41684, 467, 4, 245, 85, 189, 28, 303, 11, 10, 1203, 118, 43251, 11582, 10172, 438, 927, 346, 9, 1484, 19, 13109, 25599, 642, 22423, 4, 401, 12, 398, 20, 2621, 9, 34049, 30960, 11, 1484, 19, 3319, 34049, 31119, 876, 808, 13310, 16, 3059, 19, 1130, 15812, 4, 401, 6, 466, 3646, 403, 651, 33, 2628, 571, 12, 821, 11718, 14, 1416, 9, 34049, 39929, 2617, 8944, 12, 8556, 19, 37345, 139, 12228, 2196, 189, 1888, 5, 672, 9, 34049, 30960, 2156, 158, 12, 1558, 217, 11, 1484, 3032, 19, 50267, 31957, 1342, 260, 50268, 22446, 50, 19, 97, 3951, 12, 475, 4189, 4, 1092, 6, 1570, 6, 996, 598, 3094, 549, 41647, 1342, 260, 21, 2375, 11, 8959, 208, 30638, 2156, 52, 3744, 10, 1457, 12, 7709, 2156, 26231, 12, 9947, 1500, 9, 5, 2936, 2, 2, 2], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=None, label=0)\n",
      "\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - Feature2:\n",
      "InputFeatures(input_ids=[0, 40683, 132, 250, 13905, 10, 1203, 118, 43251, 11582, 10172, 438, 927, 1874, 11, 5, 5931, 1266, 1164, 13, 1484, 50265, 13033, 118, 43251, 11582, 10172, 438, 927, 1874, 11, 5, 5931, 1266, 1164, 50266, 45009, 262, 4, 134, 15408, 289, 571, 25606, 545, 688, 2156, 50267, 2881, 46710, 290, 4, 398, 15408, 289, 571, 50268, 131, 221, 2156, 479, 4197, 4839, 479, 2, 2, 15197, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\n",
      "\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - Feature3:\n",
      "InputFeatures(input_ids=[0, 40683, 132, 387, 13905, 117, 1203, 118, 43251, 11582, 10172, 438, 927, 464, 11, 5, 5931, 1266, 1164, 13, 1484, 3032, 19, 50265, 2362, 1203, 118, 43251, 11582, 10172, 438, 927, 464, 11, 5, 5931, 1266, 1164, 50266, 725, 571, 25606, 545, 688, 2156, 1105, 46710, 231, 4, 246, 15408, 289, 571, 25606, 221, 4, 479, 2546, 4839, 479, 2, 2, 15197, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\n",
      "\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - load dev data from cached file: ClinicalTransformerRelationExtraction/CRE_PAH/v7/cached_roberta_0_256_roberta-base_dev.pkl\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - Feature1:\n",
      "InputFeatures(input_ids=[0, 1121, 49, 892, 36, 36392, 12, 134, 2156, 579, 30880, 12, 295, 2001, 718, 7627, 11, 5931, 725, 4839, 2156, 37481, 1484, 19, 5931, 725, 36, 1169, 13561, 28119, 2681, 636, 5931, 725, 50, 5931, 725, 3059, 19, 4686, 2088, 11576, 2199, 50, 19, 21298, 36764, 8632, 18029, 12, 560, 12, 642, 922, 43462, 23795, 1872, 4839, 7, 26231, 50, 29403, 7954, 579, 9683, 225, 2001, 718, 36, 50265, 844, 2156, 843, 2156, 50, 1812, 17844, 50266, 43, 58, 43016, 576, 130, 498, 1230, 50267, 1990, 316, 688, 50268, 2, 2, 5320, 49426, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=0)\n",
      "\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - Feature2:\n",
      "InputFeatures(input_ids=[0, 6179, 12, 655, 2156, 13, 5, 37105, 36, 231, 7606, 4839, 2006, 19, 9715, 11, 42, 43630, 11798, 892, 2156, 10, 132, 12, 180, 50265, 119, 48196, 50266, 1116, 50267, 1092, 4, 245, 7606, 50268, 7325, 431, 2156, 61, 21, 34852, 19, 475, 510, 591, 3030, 30, 248, 13459, 479, 2, 2, 15197, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\n",
      "\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - Feature3:\n",
      "InputFeatures(input_ids=[0, 250, 858, 28690, 35067, 1282, 19, 50265, 2544, 763, 2987, 1827, 50266, 50267, 4892, 22398, 12572, 50268, 260, 31263, 29, 34, 57, 431, 4, 306, 4680, 15244, 2614, 33915, 45572, 36, 41647, 1342, 260, 8, 524, 39927, 1342, 260, 4839, 2156, 3660, 23, 5, 4878, 9, 253, 15244, 2614, 12, 134, 2383, 26914, 37345, 33955, 620, 44896, 2156, 58, 341, 25, 6154, 18189, 50, 11, 4069, 19, 579, 9683, 225, 2001, 718, 13, 231, 377, 2156, 5203, 11, 10, 843, 12, 119, 712, 11, 231, 19454, 495, 11, 10, 33777, 266, 9, 501, 1484, 19, 4998, 495, 4, 3305, 4129, 33839, 27799, 1334, 3175, 1907, 195, 34596, 48079, 12, 21691, 579, 9683, 225, 2001, 718, 2097, 5, 9336, 9, 740, 534, 7629, 11, 5, 34049, 37345, 13300, 18830, 2156, 15550, 8228, 12, 43728, 37345, 1688, 462, 3631, 1258, 4, 246, 6, 1898, 208, 9683, 225, 2001, 718, 16, 2033, 30, 5, 7985, 13, 304, 11, 10439, 7, 7212, 5931, 725, 2156, 19, 414, 7, 323, 103, 801, 1796, 11, 97, 4620, 9, 9715, 8, 11, 1144, 2988, 4, 1898, 83, 4792, 892, 9, 579, 9683, 225, 2001, 718, 11, 316, 4998, 250, 1484, 19, 10, 1266, 5758, 846, 8061, 155, 4, 288, 475, 73, 29, 8, 475, 510, 591, 9, 1718, 15408, 725, 571, 7646, 10, 1266, 3855, 11, 231, 19454, 495, 9, 7004, 7679, 71, 231, 377, 479, 4059, 1216, 414, 8, 38104, 676, 5256, 538, 3222, 31370, 7341, 13, 9715, 11, 4998, 250, 479, 2, 2, 43929, 2, 1, 1, 1, 1, 1], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], token_type_ids=None, label=1)\n",
      "\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - The optimizer detail:\n",
      " AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 1e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0.1\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 1e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - Model Config:\n",
      "RobertaConfig {\n",
      "  \"REModelVersion\": \"0.1\",\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"balance_sample_weights\": false,\n",
      "  \"binary_mode\": false,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"focal_loss_gamma\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"scheme\": 1,\n",
      "  \"tags\": [\n",
      "    50265,\n",
      "    50266,\n",
      "    50267,\n",
      "    50268\n",
      "  ],\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"use_focal_loss\": false,\n",
      "  \"vocab_size\": 50269\n",
      "}\n",
      "\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - All parameters:\n",
      "Namespace(adam_epsilon=1e-08, balance_sample_weights=False, cache_data=True, classification_scheme=1, data_dir='ClinicalTransformerRelationExtraction/CRE_PAH/v7/', data_file_header=True, data_format_mode=0, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_predict=False, do_train=True, do_warmup=True, eval_batch_size=16, focal_loss_gamma=2, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=1e-05, log_file='ClinicalTransformerRelationExtraction/roberta_re/v7.6/log.txt', log_lvl='i', log_step=1000, logger=<Logger Transformer_Relation_Extraction (INFO)>, max_grad_norm=1.0, max_num_checkpoints=1, max_seq_length=256, model_type='roberta', new_model_dir='ClinicalTransformerRelationExtraction/roberta_re/v7.6', non_relation_label='NotRel', num_core=1, num_train_epochs=25, overwrite_model_dir=True, predict_output_file='ClinicalTransformerRelationExtraction/roberta_re/v7.6/predictions.txt', pretrained_model='roberta-base', progress_bar=False, seed=13, train_batch_size=16, use_binary_classification_mode=False, use_focal_loss=False, warmup_ratio=14.0, weight_decay=0.1)\n",
      "2022-12-18 05:35:39 - Transformer_Relation_Extraction - INFO - start training...\n",
      "2022-12-18 05:37:40 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:37:48 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 1\n",
      "                evaluation on dev set\n",
      "                acc: 0.7048192771084337\n",
      "                precision: 0.7307692307692307; recall: 0.9421487603305785; f1:0.8231046931407942\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:39:56 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:40:04 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 2\n",
      "                evaluation on dev set\n",
      "                acc: 0.7198795180722891\n",
      "                precision: 0.7328125; recall: 0.96900826446281; f1:0.8345195729537366\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:42:12 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:42:20 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 3\n",
      "                evaluation on dev set\n",
      "                acc: 0.7048192771084337\n",
      "                precision: 0.725; recall: 0.9586776859504132; f1:0.8256227758007118\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:44:22 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:44:31 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 4\n",
      "                evaluation on dev set\n",
      "                acc: 0.7123493975903614\n",
      "                precision: 0.7278382581648523; recall: 0.9669421487603306; f1:0.8305235137533274\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:46:31 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:46:40 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 5\n",
      "                evaluation on dev set\n",
      "                acc: 0.7153614457831325\n",
      "                precision: 0.7286821705426356; recall: 0.9710743801652892; f1:0.8325952170062001\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:48:41 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:48:50 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 6\n",
      "                evaluation on dev set\n",
      "                acc: 0.7198795180722891\n",
      "                precision: 0.7313664596273292; recall: 0.9731404958677686; f1:0.8351063829787234\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:50:57 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:51:06 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 7\n",
      "                evaluation on dev set\n",
      "                acc: 0.713855421686747\n",
      "                precision: 0.7289719626168224; recall: 0.9669421487603306; f1:0.8312611012433392\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:53:08 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:53:17 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 8\n",
      "                evaluation on dev set\n",
      "                acc: 0.7078313253012049\n",
      "                precision: 0.7258566978193146; recall: 0.9628099173553719; f1:0.827708703374778\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:55:19 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:55:28 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 9\n",
      "                evaluation on dev set\n",
      "                acc: 0.7183734939759037\n",
      "                precision: 0.7316692667706708; recall: 0.96900826446281; f1:0.8337777777777777\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:57:30 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:57:39 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 10\n",
      "                evaluation on dev set\n",
      "                acc: 0.7168674698795181\n",
      "                precision: 0.7298136645962733; recall: 0.9710743801652892; f1:0.8333333333333334\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 05:59:41 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 05:59:49 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 11\n",
      "                evaluation on dev set\n",
      "                acc: 0.7108433734939759\n",
      "                precision: 0.7267080745341615; recall: 0.9669421487603306; f1:0.8297872340425533\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:01:51 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:02:00 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 12\n",
      "                evaluation on dev set\n",
      "                acc: 0.7153614457831325\n",
      "                precision: 0.7279752704791345; recall: 0.9731404958677686; f1:0.8328912466843502\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:04:02 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:04:11 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 13\n",
      "                evaluation on dev set\n",
      "                acc: 0.7228915662650602\n",
      "                precision: 0.7307692307692307; recall: 0.981404958677686; f1:0.8377425044091711\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:06:19 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:06:27 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 14\n",
      "                evaluation on dev set\n",
      "                acc: 0.7063253012048193\n",
      "                precision: 0.7254290171606864; recall: 0.9607438016528925; f1:0.8266666666666667\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:08:28 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:08:37 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 15\n",
      "                evaluation on dev set\n",
      "                acc: 0.7198795180722891\n",
      "                precision: 0.7306501547987616; recall: 0.9752066115702479; f1:0.8353982300884956\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:10:37 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:10:46 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 16\n",
      "                evaluation on dev set\n",
      "                acc: 0.7198795180722891\n",
      "                precision: 0.7350157728706624; recall: 0.9628099173553719; f1:0.8336314847942755\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:12:46 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:12:55 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 17\n",
      "                evaluation on dev set\n",
      "                acc: 0.7198795180722891\n",
      "                precision: 0.7328125; recall: 0.96900826446281; f1:0.8345195729537366\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:14:56 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:15:04 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 18\n",
      "                evaluation on dev set\n",
      "                acc: 0.7198795180722891\n",
      "                precision: 0.7357594936708861; recall: 0.9607438016528925; f1:0.8333333333333334\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:16:59 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:17:07 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 19\n",
      "                evaluation on dev set\n",
      "                acc: 0.7228915662650602\n",
      "                precision: 0.7396166134185304; recall: 0.9566115702479339; f1:0.8342342342342342\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:18:57 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:19:04 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 20\n",
      "                evaluation on dev set\n",
      "                acc: 0.7168674698795181\n",
      "                precision: 0.7402597402597403; recall: 0.9421487603305785; f1:0.8290909090909091\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:20:56 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:21:04 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 21\n",
      "                evaluation on dev set\n",
      "                acc: 0.713855421686747\n",
      "                precision: 0.7491525423728813; recall: 0.9132231404958677; f1:0.8230912476722533\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:23:02 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:23:11 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 22\n",
      "                evaluation on dev set\n",
      "                acc: 0.7123493975903614\n",
      "                precision: 0.7495741056218058; recall: 0.9090909090909091; f1:0.8216619981325863\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:25:12 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:25:21 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 23\n",
      "                evaluation on dev set\n",
      "                acc: 0.7048192771084337\n",
      "                precision: 0.7526315789473684; recall: 0.8863636363636364; f1:0.8140417457305503\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:27:23 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:27:31 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 24\n",
      "                evaluation on dev set\n",
      "                acc: 0.6987951807228916\n",
      "                precision: 0.75; recall: 0.8801652892561983; f1:0.8098859315589353\n",
      "                ******************************\n",
      "                \n",
      "2022-12-18 06:29:32 - Transformer_Relation_Extraction - INFO - start evaluation...\n",
      "2022-12-18 06:29:41 - Transformer_Relation_Extraction - INFO - \n",
      "                ******************************\n",
      "                Epoch: 25\n",
      "                evaluation on dev set\n",
      "                acc: 0.7003012048192772\n",
      "                precision: 0.7411167512690355; recall: 0.9049586776859504; f1:0.8148837209302326\n",
      "                ******************************\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "##TRAIN\n",
    "import os\n",
    "CUDA_VISIBLE_DEVICES = 1\n",
    "!env data_dir=ClinicalTransformerRelationExtraction/CRE_PAH/\n",
    "!env nmd=ClinicalTransformerRelationExtraction/roberta_re\n",
    "!env pof=predictions.txt\n",
    "!env log=log.txt\n",
    "\n",
    "# NOTE: we have more options available, you can check our wiki for more information\n",
    "!python ClinicalTransformerRelationExtraction/src/relation_extraction.py \\\n",
    "--model_type roberta \\\n",
    "--data_format_mode 0 \\\n",
    "--adam_epsilon=1e-08 \\\n",
    "--classification_scheme 1 \\\n",
    "--pretrained_model roberta-base \\\n",
    "--data_dir \"ClinicalTransformerRelationExtraction/CRE_PAH/v7/\" \\\n",
    "--new_model_dir \"ClinicalTransformerRelationExtraction/roberta_re/v7.6\" \\\n",
    "--predict_output_file \"ClinicalTransformerRelationExtraction/roberta_re/v7.6/predictions.txt\" \\\n",
    "--overwrite_model_dir \\\n",
    "--seed 13 \\\n",
    "--max_seq_length 256 \\\n",
    "--cache_data \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--do_lower_case \\\n",
    "--train_batch_size 16 \\\n",
    "--eval_batch_size 16 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 25 \\\n",
    "--gradient_accumulation_steps 1 \\\n",
    "--do_warmup \\\n",
    "--warmup_ratio 14 \\\n",
    "--weight_decay 0.1 \\\n",
    "--max_num_checkpoints 0 \\\n",
    "--log_file \"ClinicalTransformerRelationExtraction/roberta_re/v7.6/log.txt\" \\\n",
    "--non_relation_label NotRel \\\n",
    "--data_file_header False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8101dd8-407c-4278-b8da-ea41c0693ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHELL=/bin/bash\n",
      "NVIDIA_VISIBLE_DEVICES=all\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/_sagemaker-instance-credentials/a028f70afffe2e512050cbca6a6d34b6382542d1381dedd67bbb5ef26745f5b7\n",
      "PYTHONNOUSERSITE=0\n",
      "HOSTNAME=datascience-1-0-ml-g4dn-xlarge-94fad2f4401e538ca1255dfa1e84\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE=0\n",
      "SAGEMAKER_LOG_FILE=/var/log/studio/kernel_gateway.log\n",
      "AWS_DEFAULT_REGION=us-east-1\n",
      "KERNEL_WORKING_PATH=\n",
      "KERNEL_LAUNCH_TIMEOUT=40\n",
      "AWS_REGION=us-east-1\n",
      "PWD=/root\n",
      "REGION_NAME=us-east-1\n",
      "AWS_INTERNAL_IMAGE_OWNER=Studio\n",
      "HOME=/root\n",
      "LANG=C.UTF-8\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "CLICOLOR=1\n",
      "JPY_PARENT_PID=9\n",
      "TERM=xterm-color\n",
      "GIT_PAGER=cat\n",
      "CONDA_MD5=d63adf39f2c220950a063e0529d4ff74\n",
      "AWS_ACCOUNT_ID=713511755762\n",
      "SHLVL=0\n",
      "PAGER=cat\n",
      "CONDA_DIR=/opt/.sagemakerinternal/conda\n",
      "KERNEL_GATEWAY=1\n",
      "JUPYTER_PATH=/opt/conda/share/jupyter/\n",
      "MPLBACKEND=module://ipykernel.pylab.backend_inline\n",
      "CONDA_VERSION=py38_4.8.3\n",
      "LC_ALL=C.UTF-8\n",
      "PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin\n",
      "DEBIAN_FRONTEND=noninteractive\n",
      "_=/usr/bin/env\n",
      "data_dir=ClinicalTransformerRelationExtraction/CRE_PAH/\n",
      "SHELL=/bin/bash\n",
      "NVIDIA_VISIBLE_DEVICES=all\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/_sagemaker-instance-credentials/a028f70afffe2e512050cbca6a6d34b6382542d1381dedd67bbb5ef26745f5b7\n",
      "PYTHONNOUSERSITE=0\n",
      "HOSTNAME=datascience-1-0-ml-g4dn-xlarge-94fad2f4401e538ca1255dfa1e84\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE=0\n",
      "SAGEMAKER_LOG_FILE=/var/log/studio/kernel_gateway.log\n",
      "AWS_DEFAULT_REGION=us-east-1\n",
      "KERNEL_WORKING_PATH=\n",
      "KERNEL_LAUNCH_TIMEOUT=40\n",
      "AWS_REGION=us-east-1\n",
      "PWD=/root\n",
      "REGION_NAME=us-east-1\n",
      "AWS_INTERNAL_IMAGE_OWNER=Studio\n",
      "HOME=/root\n",
      "LANG=C.UTF-8\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "CLICOLOR=1\n",
      "JPY_PARENT_PID=9\n",
      "TERM=xterm-color\n",
      "GIT_PAGER=cat\n",
      "CONDA_MD5=d63adf39f2c220950a063e0529d4ff74\n",
      "AWS_ACCOUNT_ID=713511755762\n",
      "SHLVL=0\n",
      "PAGER=cat\n",
      "CONDA_DIR=/opt/.sagemakerinternal/conda\n",
      "KERNEL_GATEWAY=1\n",
      "JUPYTER_PATH=/opt/conda/share/jupyter/\n",
      "MPLBACKEND=module://ipykernel.pylab.backend_inline\n",
      "CONDA_VERSION=py38_4.8.3\n",
      "LC_ALL=C.UTF-8\n",
      "PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin\n",
      "DEBIAN_FRONTEND=noninteractive\n",
      "_=/usr/bin/env\n",
      "nmd=ClinicalTransformerRelationExtraction/roberta_re\n",
      "SHELL=/bin/bash\n",
      "NVIDIA_VISIBLE_DEVICES=all\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/_sagemaker-instance-credentials/a028f70afffe2e512050cbca6a6d34b6382542d1381dedd67bbb5ef26745f5b7\n",
      "PYTHONNOUSERSITE=0\n",
      "HOSTNAME=datascience-1-0-ml-g4dn-xlarge-94fad2f4401e538ca1255dfa1e84\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE=0\n",
      "SAGEMAKER_LOG_FILE=/var/log/studio/kernel_gateway.log\n",
      "AWS_DEFAULT_REGION=us-east-1\n",
      "KERNEL_WORKING_PATH=\n",
      "KERNEL_LAUNCH_TIMEOUT=40\n",
      "AWS_REGION=us-east-1\n",
      "PWD=/root\n",
      "REGION_NAME=us-east-1\n",
      "AWS_INTERNAL_IMAGE_OWNER=Studio\n",
      "HOME=/root\n",
      "LANG=C.UTF-8\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "CLICOLOR=1\n",
      "JPY_PARENT_PID=9\n",
      "TERM=xterm-color\n",
      "GIT_PAGER=cat\n",
      "CONDA_MD5=d63adf39f2c220950a063e0529d4ff74\n",
      "AWS_ACCOUNT_ID=713511755762\n",
      "SHLVL=0\n",
      "PAGER=cat\n",
      "CONDA_DIR=/opt/.sagemakerinternal/conda\n",
      "KERNEL_GATEWAY=1\n",
      "JUPYTER_PATH=/opt/conda/share/jupyter/\n",
      "MPLBACKEND=module://ipykernel.pylab.backend_inline\n",
      "CONDA_VERSION=py38_4.8.3\n",
      "LC_ALL=C.UTF-8\n",
      "PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin\n",
      "DEBIAN_FRONTEND=noninteractive\n",
      "_=/usr/bin/env\n",
      "pof=predictions.txt\n",
      "SHELL=/bin/bash\n",
      "NVIDIA_VISIBLE_DEVICES=all\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/_sagemaker-instance-credentials/a028f70afffe2e512050cbca6a6d34b6382542d1381dedd67bbb5ef26745f5b7\n",
      "PYTHONNOUSERSITE=0\n",
      "HOSTNAME=datascience-1-0-ml-g4dn-xlarge-94fad2f4401e538ca1255dfa1e84\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE=0\n",
      "SAGEMAKER_LOG_FILE=/var/log/studio/kernel_gateway.log\n",
      "AWS_DEFAULT_REGION=us-east-1\n",
      "KERNEL_WORKING_PATH=\n",
      "KERNEL_LAUNCH_TIMEOUT=40\n",
      "AWS_REGION=us-east-1\n",
      "PWD=/root\n",
      "REGION_NAME=us-east-1\n",
      "AWS_INTERNAL_IMAGE_OWNER=Studio\n",
      "HOME=/root\n",
      "LANG=C.UTF-8\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "CLICOLOR=1\n",
      "JPY_PARENT_PID=9\n",
      "TERM=xterm-color\n",
      "GIT_PAGER=cat\n",
      "CONDA_MD5=d63adf39f2c220950a063e0529d4ff74\n",
      "AWS_ACCOUNT_ID=713511755762\n",
      "SHLVL=0\n",
      "PAGER=cat\n",
      "CONDA_DIR=/opt/.sagemakerinternal/conda\n",
      "KERNEL_GATEWAY=1\n",
      "JUPYTER_PATH=/opt/conda/share/jupyter/\n",
      "MPLBACKEND=module://ipykernel.pylab.backend_inline\n",
      "CONDA_VERSION=py38_4.8.3\n",
      "LC_ALL=C.UTF-8\n",
      "PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin\n",
      "DEBIAN_FRONTEND=noninteractive\n",
      "_=/usr/bin/env\n",
      "log=log.txt\n",
      "2022-12-18 05:30:11.982375: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 05:30:12.132633: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-18 05:30:12.815323: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 05:30:12.815420: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-18 05:30:12.815441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "ClinicalTransformerRelationExtraction/src/relation_extraction.py:26: UserWarning: Evaluation mode (do_eval) should be set in order to save more than one models.We will evaluate at the end of each epoch and save models with better F1-score.if do_eval is not set, we will only save one model at the end of training,in this case you have to set max_num_checkpoints=0 (default),We did this for you by setting max_num_checkpoints=0\n",
      "  warnings.warn(\"Evaluation mode (do_eval) should be set in order to save more than one models.\"\n",
      "Traceback (most recent call last):\n",
      "  File \"ClinicalTransformerRelationExtraction/src/relation_extraction.py\", line 181, in <module>\n",
      "    app(args)\n",
      "  File \"ClinicalTransformerRelationExtraction/src/relation_extraction.py\", line 54, in app\n",
      "    task_runner.task_runner_default_init()\n",
      "  File \"/root/ClinicalTransformerRelationExtraction/src/task.py\", line 64, in task_runner_default_init\n",
      "    self._init_trained_model()\n",
      "  File \"/root/ClinicalTransformerRelationExtraction/src/task.py\", line 271, in _init_trained_model\n",
      "    latest_ckpt_dir = sorted(dir_list, key=lambda x: int(x.stem.split(\"_\")[-1]))[-1]\n",
      "  File \"/root/ClinicalTransformerRelationExtraction/src/task.py\", line 271, in <lambda>\n",
      "    latest_ckpt_dir = sorted(dir_list, key=lambda x: int(x.stem.split(\"_\")[-1]))[-1]\n",
      "ValueError: invalid literal for int() with base 10: 'checkpoints'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "CUDA_VISIBLE_DEVICES = 1\n",
    "!env data_dir=ClinicalTransformerRelationExtraction/CRE_PAH/\n",
    "!env nmd=ClinicalTransformerRelationExtraction/roberta_re\n",
    "!env pof=predictions.txt\n",
    "!env log=log.txt\n",
    "\n",
    "# NOTE: we have more options available, you can check our wiki for more information\n",
    "!python ClinicalTransformerRelationExtraction/src/relation_extraction.py \\\n",
    "--model_type roberta \\\n",
    "--data_format_mode 0 \\\n",
    "--classification_scheme 1 \\\n",
    "--pretrained_model ClinicalTransformerRelationExtraction/roberta_re/v7.6/ckpt_13 \\\n",
    "--data_dir \"ClinicalTransformerRelationExtraction/CRE_PAH/v7/\" \\\n",
    "--new_model_dir \"ClinicalTransformerRelationExtraction/roberta_re/v7.6/\" \\\n",
    "--predict_output_file \"ClinicalTransformerRelationExtraction/predictions_split.txt\" \\\n",
    "--overwrite_model_dir \\\n",
    "--seed 13 \\\n",
    "--max_seq_length 256 \\\n",
    "--cache_data \\\n",
    "--do_predict \\\n",
    "--do_lower_case \\\n",
    "--train_batch_size 16 \\\n",
    "--eval_batch_size 16 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--num_train_epochs 40 \\\n",
    "--gradient_accumulation_steps 1 \\\n",
    "--do_warmup \\\n",
    "--warmup_ratio 8 \\\n",
    "--weight_decay 0.1 \\\n",
    "--max_num_checkpoints 1 \\\n",
    "--log_file \"ClinicalTransformerRelationExtraction/roberta_re/v7.6/log.txt\" \\\n",
    "--non_relation_label NotRel \\\n",
    "--data_file_header 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4afb3274-df01-4691-8364-6808c4a592de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chardet\n",
    "with open('ClinicalTransformerRelationExtraction/predictions_old.txt', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
